{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dropbox\n",
    "import shutil\n",
    "import getpass\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "class Model(Enum):\n",
    "    OPEN_AI = 1\n",
    "    LLAMA = 2\n",
    "    NOMIC = 3\n",
    "\n",
    "QUERIES = [\n",
    "    \"How to deal with a memory leak in prod?\",\n",
    "    \"What are the responsibilities of the First Captain during a fire?\",\n",
    "    \"What are the First Captain's responsibilities during a fire?\",\n",
    "    \"What should I do if there are problems with the haskell quiz engine?\",\n",
    "    \"What are my responsibilites when on call?\",\n",
    "    \"What do I do if my time off conflicts with being on call?\",\n",
    "]\n",
    "\n",
    "DOWNLOAD_FOLDER = \".content\"\n",
    "TEST_CONTENT_DROPBOX_FOLDER = \"LLM Doc Exp Test Content\"\n",
    "EMBEDDINGS_MODEL = Model.NOMIC\n",
    "LLM_MODEL = Model.LLAMA\n",
    "RESET_DROPBOX = False\n",
    "RESET_VECTOR_STORE = False\n",
    "TEST_QUERY = QUERIES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import sseclient\n",
    "# import json\n",
    "\n",
    "\n",
    "# def get_stream(app, query):\n",
    "#     full_response = \"\"\n",
    "#     url = \"http://127.0.0.1:8000/query/stream_events/\"\n",
    "#     response = requests.post(url, json={\"input\": {\"query\": query}}, stream=True)\n",
    "#     client = sseclient.SSEClient(response)\n",
    "#     for event in client.events():\n",
    "#         output = json.loads(event.data)\n",
    "#         if output[\"event\"] == \"on_llm_stream\":\n",
    "#             if chunk := output[\"data\"].get(\"chunk\"):\n",
    "#                 full_response += chunk\n",
    "#                 yield full_response\n",
    "#         elif output[\"event\"] == \"on_chain_end\":\n",
    "#             if source_documents := output[\"data\"][\"output\"].get(\"source_documents\"):\n",
    "#                 yield output[\"data\"][\"output\"][\"result\"]\n",
    "\n",
    "# for chunk in get_stream(None, TEST_QUERY):\n",
    "#     print(chunk, flush=True)\n",
    "\n",
    "\n",
    "# from langserve import RemoteRunnable\n",
    "# query_chain = RemoteRunnable(\"http://127.0.0.1:8000/query/\")\n",
    "\n",
    "# async for msg in query_chain.astream({\"query\": QUERIES[0]}):\n",
    "#     print(msg, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = {\n",
    "    Model.OPEN_AI: OpenAIEmbeddings,\n",
    "    Model.LLAMA: lambda: OllamaEmbeddings(model=\"llama3\"),\n",
    "    Model.NOMIC: lambda: OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llms = {\n",
    "    Model.OPEN_AI: lambda: ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
    "    Model.LLAMA: lambda: Ollama(model=\"llama3\", temperature=0),\n",
    "    Model.NOMIC: lambda: Ollama(model=\"llama3\", temperature=0),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESET_DROPBOX:\n",
    "    dbx = dropbox.Dropbox(getpass.getpass(\"Dropbox API Key:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Open AI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure local download folder exists, and delete its contents\n",
    "\n",
    "def create_download_folder():\n",
    "    if not os.path.exists(DOWNLOAD_FOLDER):\n",
    "        os.makedirs(DOWNLOAD_FOLDER)\n",
    "\n",
    "def clear_downloads_folder():\n",
    "    for filename in os.listdir(DOWNLOAD_FOLDER):\n",
    "        file_path = os.path.join(DOWNLOAD_FOLDER, filename)\n",
    "        print(file_path)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "\n",
    "create_download_folder()\n",
    "if RESET_DROPBOX:\n",
    "    clear_downloads_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter dropbox paper docs and download to content file\n",
    "\n",
    "Download selected test paper docs using the [Dropbox API](https://www.dropbox.com/developers/documentation/http/documentation#paper-docs-download) and [Python SDK](https://dropbox-sdk-python.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "The dashboard for the Dropbox App used to do this can be found [here](https://www.dropbox.com/developers/apps/info/la3hq2wkhl5wx4m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dropbox.paper import ExportFormat\n",
    "# folders_to_match = set([\"Engineering\", \"Fires\"])\n",
    "\n",
    "# print(\"Getting doc ids\")\n",
    "# doc_ids = dbx.paper_docs_list().doc_ids\n",
    "\n",
    "# print(\"Getting docs in matching folders\")\n",
    "# docs_ids_in_folder = [doc_id for doc_id in doc_ids if folders_to_match.issubset(set([folder.name for folder in dbx.paper_docs_get_folder_info(doc_id).folders or []]))]\n",
    "\n",
    "# print(\"Getting doc titles\")\n",
    "# doc_titles = {doc_id: dbx.paper_docs_download(doc_id, ExportFormat('markdown'))[0].title for doc_id in docs_ids_in_folder}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dropbox.paper import ExportFormat, ListPaperDocsFilterBy\n",
    "\n",
    "def get_file_path(doc_id):\n",
    "    return os.path.join(DOWNLOAD_FOLDER, f\"{doc_titles[doc_id]}.md\")\n",
    "\n",
    "def download_doc(doc_id):\n",
    "    result = dbx.paper_docs_download_to_file(get_file_path(doc_id), doc_id, ExportFormat('markdown'))\n",
    "    print(f\"- downloaded '{result.title}'\")\n",
    "    return result\n",
    "\n",
    "if RESET_DROPBOX:\n",
    "    print(\"Retrieving document IDs\")\n",
    "    doc_ids = dbx.paper_docs_list(filter_by=ListPaperDocsFilterBy.docs_created).doc_ids\n",
    "    print(f\"- {len(doc_ids)} documents found\")\n",
    "\n",
    "    print(\"Filtering documents in folder\")\n",
    "    docs_ids_in_folder = [doc_id for doc_id in doc_ids if TEST_CONTENT_DROPBOX_FOLDER in [folder.name for folder in dbx.paper_docs_get_folder_info(doc_id).folders or []]]\n",
    "    print(f\"- {len(docs_ids_in_folder)} documents found in folder\")\n",
    "\n",
    "    print(\"Retrieving document titles\")\n",
    "    doc_titles = {doc_id: dbx.paper_docs_download(doc_id, ExportFormat('markdown'))[0].title for doc_id in docs_ids_in_folder}\n",
    "\n",
    "    print(\"Downloading documents\")\n",
    "    results = [download_doc(doc_id) for doc_id in docs_ids_in_folder]\n",
    "    print(\"Download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG Q&A using the downloaded files\n",
    "\n",
    "Uses [this repo](https://github.com/AI-Maker-Space/LLM-Ops-Cohort-1/blob/main/Week%201/Tuesday/Barbie_Retrieval_Augmented_Question_Answering_(RAQA)_Assignment%20(Assignment%20Version).ipynb) as a reference.\n",
    "\n",
    "\n",
    "Additional Resources:\n",
    "https://github.com/zylon-ai/private-gpt/issues/358#issuecomment-1563663500\n",
    "https://python.langchain.com/docs/integrations/vectorstores/starrocks/\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders.directory import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain_text_splitters import Language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(DOWNLOAD_FOLDER, glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader)\n",
    "\n",
    "raw_documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# headers_to_split_on = [\n",
    "#     (\"#\", \"Header 1\"),\n",
    "#     (\"##\", \"Header 2\"),\n",
    "# ]\n",
    "\n",
    "# # MD splits\n",
    "# markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "#     headers_to_split_on=headers_to_split_on, strip_headers=False\n",
    "# )\n",
    "\n",
    "# loader.load_and_split(text_splitter=markdown_splitter)\n",
    "# MarkdownTextSplitter()\n",
    "\n",
    "# # Char-level splits\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# chunk_size = 250\n",
    "# chunk_overlap = 30\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "# )\n",
    "\n",
    "# # Split\n",
    "# splits = text_splitter.split_documents(md_header_splits)\n",
    "# splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# text_splitter = MarkdownTextSplitter(\n",
    "#     chunk_size = 1000, # the character length of the chunk\n",
    "#     chunk_overlap = 100, # the character length of the overlap between chunks\n",
    "#     length_function = len, # the length function\n",
    "# )\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language(Language.MARKDOWN, \n",
    "    chunk_size = 1000, # the character length of the chunk\n",
    "    chunk_overlap = 100, # the character length of the overlap between chunks\n",
    "    length_function = len, # the length function\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='🔥 Fire triage drill\\n\\nNote: This document is not intended to be consumed by itself. I’m personally introducing fire fighters to this drill at the start of their on-call cycle, and the document is here for a) reference for me b) reference for fire fighters after our meeting.\\n\\nThe fire drill starts at the NewRelic APM main screen for the Monolith. Go through the numbers on the image, reading their description below, and follow the arrows ➡️ .\\n\\nNewRelic\\n\\nMonolith NewRelic main screen\\n\\n🔗 Link\\n\\nRequest breakdown\\nDid something start taking up a larger share of request time?\\nExternal services\\n➡️ Go to the External Services tab in the right and figure out which service\\n\\n\\nDB\\n➡️ Go to the Databases tab and see whether some transactions started spiking\\n➡️ Open RDS Performance Insights for higher resolution data\\n\\n\\nQueueing or Ruby Slowness\\n➡️ Open Load Balancers Dashboard\\n➡️ Opsworks time-based instances and load-based instances\\nDo we have instances booting up?' metadata={'source': '.content/Engineering/Fires/Fire_triage_drill.md'}\n",
      "page_content='Throughput\\nDo we have a huge spike in throughput? 200k RPM and above might mean we’re under a DDoS attack\\n➡️ Check out what to do here: +Firefighting Resources: Fighting-a-DDoS-attack\\n\\nError rate\\nAre error spiking? Like 1% or more\\n➡️ Go to Errors tab\\n➡️ Check out Bugsnag (finer grained timeline)\\n\\nExternal Services\\n\\nServices by total response time\\nAny service started taking a longer time than usual?\\nA Haskell service?\\n➡️ Go to the specific service’s dashboard in NewRelic and do a similar analysis there (what made it slow? etc)\\n➡️ Also, open the Haskell Services in Kubernete dashboard in Datadog, because Kubernetes might be at fault\\nWhat services are in Kubernetes?\\nDrafts\\nQuiz Engine\\nTutorials' metadata={'source': '.content/Engineering/Fires/Fire_triage_drill.md'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Creation\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/vectorstores/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.storage import LocalFileStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = LocalFileStore(\".cache\")\n",
    "\n",
    "core_embeddings_model = embeddings[EMBEDDINGS_MODEL]()\n",
    "\n",
    "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    core_embeddings_model, store, namespace=core_embeddings_model.model\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(documents, core_embeddings_model, normalize_L2=True)\n",
    "vector_store.save_local(\".vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistanceStrategy.EUCLIDEAN_DISTANCE\n",
      "{'page_content': '# 2016–09–30 Other (~resolved🎉?) Fires\\n\\nMemory leak in prod\\n\\nUpdate / Tentatively Resolved\\nAppears that the cause was not in the suspect list below (but in the deploy) https://github.com/NoRedInk/NoRedInk/pull/13550 which is now the primary suspect with a fix deployed in https://github.com/NoRedInk/NoRedInk/pull/13703 that thus far appears to have removed network correlated memory spikes.\\n\\nThings we can do\\n\\nDeploy/rollback to production-2016-09-29-0434\\n\\nRevert the suspect PRs\\n\\nSuspect PRs\\nFrom @Joshua L (sorted by suspicion)', 'metadata': {'source': '.content/Engineering/Fires/Old_Fires/2016–09–30_Other_(~resolved_)_Fires.md'}, 'type': 'Document'}\n",
      "{'page_content': 'Solutions/thoughts\\n\\nFree memory usage then run again\\nseems to work sometimes, othertimes does not\\n\\nOccasionally, it will build successfully\\nunable to reproduce consistently\\n\\nWiping elm-stuff prior to running webpack has no success\\n\\nTried to increase thread pool via https://github.com/jtangelder/sass-loader/issues/100#issuecomment-104081891\\nDid not change anything\\n\\nGoing to try bumping sass-loaderversion\\nsass-loader → Did not work\\n\\nDisabled sass\\nStill hitting the same problem\\nHints that the problem is elsewhere\\n\\nUsing --bail --profile --progress --display-chunks --optimize-min-chunk-size 10000 --optimize-max-chunks 1 --display-reasons', 'metadata': {'source': '.content/Engineering/Fires/Old_Fires/2016-11-30_Webpack_breaking_and_blocking_deploys.md'}, 'type': 'Document'}\n",
      "{'page_content': '--new-db-instance-identifier prod-internal-replica-old \\\\\\n      --apply-immediately \\\\\\n      --region \"us-west-2\"\\n    [x] rename prod-internal-replica-2 to prod-internal-replica\\n    aws-vault exec sudo -- aws rds modify-db-instance \\\\\\n      --db-instance-identifier prod-internal-replica2 \\\\\\n      --new-db-instance-identifier prod-internal-replica \\\\\\n      --apply-immediately \\\\\\n      --region \"us-west-2\"', 'metadata': {'source': '.content/Engineering/Fires/Old_Fires/Replication_Stopped.md'}, 'type': 'Document'}\n",
      "{'page_content': '[ ] complete the backfill\\n    - ~~investigate backfilling in id order, not grammar_quiz_question_id order (JOSH)~~\\n    - ~~investigate how to solve~~ ~~backfill contention problems~~\\n        - ~~Option 1:~~\\n            [ ] ~~Move select to replica~~\\n        - Option 2:  ← WENT WITH OPTION 2\\n            [x] set innodb_autoinc_lock_mode to 2 instead of the default value 1 (from https://dev.mysql.com/doc/refman/5.5/en/optimizing-innodb-bulk-data-loading.html)\\n            - apply type: static, which needs a reboot but won’t be a problem if we’re multi-az\\n            [x] go back to insert into … select  ← MORE THAN 2–10x FASTER\\n        - ~~Option 3 (if we still have contention)~~\\n            [ ] ~~ALTER TABLE on the old tables (Thanks @jeg)~~\\n            [ ] ~~when alter table is completed, add trigger to send new data & modifications when they come~~\\n            [ ] ~~backfill the gap~~\\n            [ ] ~~When the backfill is over, promote~~ ~~_old~~ ~~~~ ~~tables.~~', 'metadata': {'source': '.content/Engineering/Fires/Old_Fires/2016–09–28_Next_Steps_after_Live_Restore.md'}, 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "# Example query on the vector store\n",
    "print(vector_store.distance_strategy)\n",
    "\n",
    "query = TEST_QUERY\n",
    "embedding_vector = core_embeddings_model.embed_query(query)\n",
    "# docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)\n",
    "docs = vector_store.similarity_search_with_score_by_vector(embedding_vector, score_threshold=10.0)\n",
    "# docs = vector_store.similarity_search_with_score_by_vector(embedding_vector, k=4)\n",
    "\n",
    "for page in docs:\n",
    "  print(page[0].dict())\n",
    "  # print(f\">>>{page.page_content}<<<\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = llms[LLM_MODEL]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    store = LocalFileStore(\".cache\")\n",
    "\n",
    "    return CacheBackedEmbeddings.from_bytes_store(\n",
    "        core_embeddings_model, store, namespace=core_embeddings_model.model\n",
    "    )\n",
    "def load_vector_store():\n",
    "    embeddings = get_embeddings()\n",
    "    return FAISS.load_local(\n",
    "        \".vector_store\", embeddings, allow_dangerous_deserialization=True\n",
    "    )\n",
    "loaded_vector_store = load_vector_store()\n",
    "# retriever = vector_store.as_retriever()\n",
    "retriever = loaded_vector_store.as_retriever(\n",
    "    # search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={\"score_threshold\": 0.9},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = StdOutCallbackHandler()\n",
    "\n",
    "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    callbacks=[handler],\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.chains.qa_with_sources.retrieval\n",
    "import langchain.chains.retrieval_qa.base\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'What are the responsibilities of the First Captain during a fire?', 'result': \"I don't know.\", 'source_documents': []}\n"
     ]
    }
   ],
   "source": [
    "result = qa_with_sources_chain({\"query\" : QUERIES[1]})\n",
    "# from langchain_core.runnables import RunnableBranch, RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# def get_context_from_documents(documents):\n",
    "#     document_separator = \"\\n\\n\"\n",
    "#     return document_separator.join(f\"Document {i}:\\n{doc.page_content}\" for i, doc in enumerate(documents))\n",
    "\n",
    "\n",
    "# context_chain = RunnablePassthrough.assign(context=lambda x: get_context_from_documents(x[\"source_documents\"]))\n",
    "# chain = qa_with_sources_chain | context_chain\n",
    "# result = chain.invoke(TEST_QUERY)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, MessagesPlaceholder, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch, RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "RESPONSE_TEMPLATE = \"\"\"\\\n",
    "You are an expert programmer and problem-solver, tasked with answering any question \\\n",
    "about Langchain.\n",
    "\n",
    "Generate a comprehensive and informative answer of 80 words or less for the \\\n",
    "given question based solely on the provided search results (URL and content). You must \\\n",
    "only use information from the provided search results. Use an unbiased and \\\n",
    "journalistic tone. Combine search results together into a coherent answer. Do not \\\n",
    "repeat text. Cite search results using [${{number}}] notation. Only cite the most \\\n",
    "relevant results that answer the question accurately. Place these citations at the end \\\n",
    "of the sentence or paragraph that reference them - do not put them all at the end. If \\\n",
    "different results refer to different entities within the same name, write separate \\\n",
    "answers for each entity.\n",
    "\n",
    "You should use bullet points in your answer for readability. Put citations where they apply\n",
    "rather than putting them all at the end.\n",
    "\n",
    "If there is nothing in the context relevant to the question at hand, just say \"Hmm, \\\n",
    "I'm not sure.\" Don't try to make up an answer.\n",
    "\n",
    "Anything between the following `context`  html blocks is retrieved from a knowledge \\\n",
    "bank, not part of the conversation with the user. \n",
    "\n",
    "<context>\n",
    "    {context} \n",
    "<context/>\n",
    "\n",
    "REMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm \\\n",
    "not sure.\" Don't try to make up an answer. Anything between the preceding 'context' \\\n",
    "html blocks is retrieved from a knowledge bank, not part of the conversation with the \\\n",
    "user.\\\n",
    "\"\"\"\n",
    "\n",
    "REPHRASE_TEMPLATE = \"\"\"\\\n",
    "Given the following conversation and a follow up question, rephrase the follow up \\\n",
    "question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone Question:\"\"\"\n",
    "\n",
    "def format_docs(docs) -> str:\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        doc_string = f\"<doc id='{i}'>{doc.page_content}</doc>\"\n",
    "        formatted_docs.append(doc_string)\n",
    "    return \"\\n\".join(formatted_docs)\n",
    "\n",
    "def serialize_history(request):\n",
    "    chat_history = request[\"chat_history\"] or []\n",
    "    converted_chat_history = []\n",
    "    for message in chat_history:\n",
    "        if message.get(\"human\") is not None:\n",
    "            converted_chat_history.append(HumanMessage(content=message[\"human\"]))\n",
    "        if message.get(\"ai\") is not None:\n",
    "            converted_chat_history.append(AIMessage(content=message[\"ai\"]))\n",
    "    return converted_chat_history\n",
    "\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(REPHRASE_TEMPLATE)\n",
    "condense_question_chain = (\n",
    "    CONDENSE_QUESTION_PROMPT | llm | StrOutputParser()\n",
    ").with_config(\n",
    "    run_name=\"CondenseQuestion\",\n",
    ")\n",
    "conversation_chain = condense_question_chain | retriever\n",
    "retriever_chain = RunnableBranch(\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),\n",
    "        conversation_chain.with_config(run_name=\"RetrievalChainWithHistory\"),\n",
    "    ),\n",
    "    (\n",
    "        RunnableLambda(itemgetter(\"question\")).with_config(\n",
    "            run_name=\"Itemgetter:question\"\n",
    "        )\n",
    "        | retriever\n",
    "    ).with_config(run_name=\"RetrievalChainWithNoHistory\"),\n",
    ").with_config(run_name=\"RouteDependingOnChatHistory\")\n",
    "\n",
    "\n",
    "context = (\n",
    "    RunnablePassthrough.assign(docs=retriever_chain)\n",
    "    .assign(context=lambda x: format_docs(x[\"docs\"]))\n",
    "    .with_config(run_name=\"RetrieveDocs\")\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", RESPONSE_TEMPLATE),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "default_response_synthesizer = prompt | llm\n",
    "\n",
    "chain = RunnablePassthrough.assign(chat_history=serialize_history) | context | default_response_synthesizer\n",
    "\n",
    "chain.run({\"question\": \"How to deal with a memory leak in prod?\", \"chat_history\": []})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throughput\n",
      "Do we have a huge spike in throughput? 200k RPM and above might mean we’re under a DDoS attack\n",
      "➡️ Check out what to do here: +Firefighting Resources: Fighting-a-DDoS-attack\n",
      "\n",
      "Error rate\n",
      "Are error spiking? Like 1% or more\n",
      "➡️ Go to Errors tab\n",
      "➡️ Check out Bugsnag (finer grained timeline)\n",
      "\n",
      "External Services\n",
      "\n",
      "Services by total response time\n",
      "Any service started taking a longer time than usual?\n",
      "A Haskell service?\n",
      "➡️ Go to the specific service’s dashboard in NewRelic and do a similar analysis there (what made it slow? etc)\n",
      "➡️ Also, open the Haskell Services in Kubernete dashboard in Datadog, because Kubernetes might be at fault\n",
      "What services are in Kubernetes?\n",
      "Drafts\n",
      "Quiz Engine\n",
      "Tutorials\n",
      "=====================\n",
      "Here is the cleaned content:\n",
      "```\n",
      "# Throughput\n",
      "## Huge Spike in Throughput?\n",
      "If we have a throughput of 200k RPM or above, it might indicate a DDoS attack. Check out firefighting resources for guidance.\n",
      "\n",
      "# Error Rate\n",
      "## High Error Rates?\n",
      "If error rates are spiking at 1% or more, go to the Errors tab and check Bugsnag for a finer-grained timeline.\n",
      "\n",
      "# External Services\n",
      "## Services by Total Response Time\n",
      "Are any services taking longer than usual? Check the specific service's dashboard in NewRelic for analysis. Also, open the Haskell Services in Kubernete dashboard in Datadog, as Kubernetes might be at fault.\n",
      "## What Services are in Kubernetes?\n",
      "\n",
      "# Drafts\n",
      "## Quiz Engine\n",
      "## Tutorials\n",
      "```\n",
      "I removed emojis, expanded abbreviations and acronyms of common words, removed bold and italic text styling, formatted section headers using hierarchical hashtags, and made other cleaning optimizations to prepare the content for embedding as part of a RAG LLM application.\n"
     ]
    }
   ],
   "source": [
    "print(documents[1].page_content)\n",
    "print(\"=====================\")\n",
    "prompt = f\"\"\"Please help clean the following content in preparation for embedding as part of a RAG LLM application:\n",
    "- remove emojis\n",
    "- expand abbreviations and acronyms of common words\n",
    "- remove bold and italic text styling\n",
    "- section headers should be formatted using hierarchical hashtags instead of being underlined\n",
    "- any other cleaning optimisations\n",
    "\n",
    "Your answer MUST be in valid and well structured markdown and delimited by triple backticks (```).\n",
    "Your answer MUST contain ALL factual information, and should serve as a faithful functional replacement of the original.\n",
    "\n",
    "CONTENT:\n",
    "```\n",
    "Example topic\n",
    "=============\n",
    "\n",
    "irrelevant note\n",
    "\n",
    "**first topic**\n",
    "first info\n",
    "some info\n",
    "- list item 1\n",
    "- list item 2\n",
    "\n",
    "**second topic**\n",
    "more info\n",
    "```\n",
    "\n",
    "CLEANED:\n",
    "```\n",
    "# Example topic\n",
    "\n",
    "## first topic\n",
    "first information\n",
    "some information\n",
    "- list item 1\n",
    "- list item 2\n",
    "\n",
    "## second topic\n",
    "more information\n",
    "```\n",
    "\n",
    "CONTENT:\n",
    "```\n",
    "{documents[1].page_content}\n",
    "```\n",
    "\n",
    "CLEANED:\n",
    "\"\"\"\n",
    "# print(documents[0].page_content)\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mandlamoyo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mandlamoyo/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fires checklist\n",
      "\n",
      "[ ] Join https://appear.in/nri-fix-the-fire\n",
      "[ ] Join #fix-the-fire\n",
      "[ ] If there’s no captain, elect a captain (preferably someone who is on call)\n",
      "[ ] Use either the captain’s or firefighter’s checklist below\n",
      "\n",
      "Captain Checklists & Info\n",
      "\n",
      "Using QA\n",
      "\n",
      "During fires, there is generally no explicit QA schedule as it is impossible to know exactly when fixes will be available. QA can be requested ad hoc.\n",
      "\n",
      "When recovering from a fire and the code has been hot deployed or the maintenance page has been used, it’s advisable to do full QA on the production site when we think everything is back to normal.\n",
      "\n",
      "If the site is severely degraded, it may be OK to deploy a fix without QA. Risking regressions isn’t a serious concern if the site is mostly unusable. That being said: Code Review should still be observed & the staging environment should still be used to test changes against production data when necessary. @blunderdome can support in finding the type of data you want to test something manually.\n",
      "\n",
      "First Captain\n",
      "\n",
      "[ ] Start keeping notes in +Fire Progress. Keep in mind this document will be used for the fires write-up. \n",
      "[ ] try to make a rough estimate of when the fire will be over:\n",
      "    - If it will take multiple days\n",
      "        [ ] confirm availability with firefighters\n",
      "        [ ] confirm next captain in yours and the next time zone\n",
      "    [ ] notify #support with your estimate\n",
      "[ ] If firefighting can use more than 2 people, start a planning meeting.\n",
      "[ ] notify #support with\n",
      "    [ ] predicted length of outage\n",
      "    [ ] predicted affected # users\n",
      "    [ ] cause of outage (for communication with customers)\n",
      "\n",
      "Captain Hand-Off\n",
      "\n",
      "[ ] Pin the new captain to #fix-the-fires.\n",
      "[ ] Ensure the current validity of +Fire Progress\n",
      "    - if there is a time-zone gap, do hand-off via @notification in slack.\n",
      "    [ ] Ensure abandoned in-progress work gets marked “available”\n",
      "[ ] If necessary, confirm a next captain\n",
      "\n",
      "While Captain\n",
      "\n",
      "[ ] if there are multiple concurrent fires, split +Fire Progress into different docs. Name the new docs “Year-Month-Date The Cause of the Fire Fire” and add to +In Progress \n",
      "    [ ]  and link them in Fire Progress.\n",
      "[ ] if the site\n",
      "\n",
      "Every 2–3 hours\n",
      "\n",
      "invite all firefighters to https://appear.in/nri-fix-the-fire\n",
      "    [ ] for multi-day fires, ensure firefighters are sleeping \n",
      "    [ ] give status updates\n",
      "    [ ] ensure everyone has a task\n",
      "        [ ] If we need to make product decisions, try to pull someone from #support or #product in\n",
      "    [ ] if there’s room for more fire fighters, ask in #eduneering\n",
      "    [ ] break off again into small groups to fix problems\n",
      "[ ] update #support with any news / explicitly no news\n",
      "    [ ] if there are database queries we want to monitor across-teams, consider using Metabase’s pulse feature.\n",
      "[ ] ensure +Fire Progress is up to date\n",
      "\n",
      "Last Captain\n",
      "\n",
      "[ ] archive the contents +Fire Progress into a new file, titled “Year-Month-Date The Cause of the Fire Fire” and put in +Old Fires folder.\n",
      "[ ] move completed +In Progress  to +Old Fires, too.\n",
      "- issue fire write up on the eng-internal pivotal tracker\n",
      "    [ ] label: “fire follow-up”\n",
      "    [ ] notify at least one junior and all firefighters for review\n",
      "    [ ] link the fires doc\n",
      "[ ] schedule retro with all firefighters\n",
      "[ ] issue cleanup work in eng-internal pivotal, label “fire follow-up” and put it directly in the backlog\n",
      "\n",
      "Firefighter Checklist\n",
      "\n",
      "[ ] ask captain for a next step\n",
      "[ ] If there are ops-ey next steps, ensure their specific syntax is fleshed out.\n",
      "[ ] when you’re done, inform the captain and get a next task\n",
      "    [ ] if they’re not available, peel from unassigned tasks in paper\n",
      "\n",
      "How can I help as a non-ops\n",
      "\n",
      "[ ] offer to pair/observe with ops (helps transfer knowledge)\n",
      "\n",
      "If you need information about the Fire\n",
      "\n",
      "[ ] ask in #fire-updates\n",
      "[ ] enable slack notifications in #fire-updates\n",
      "[ ] Ask the current fire captain (pinned in #fix-the-fires)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "d = raw_documents[7].copy()\n",
    "print(d.page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['firefighting', 'resource', 'big', 'list', 'alert', 'type', 'response', 'playbook', 'slack', 'engopschanges', 'information', 'manually', 'performed', 'operation', 'may', 'caused', 'alert', 'askteamfoxen', 'slack', 'channel', 'infrastructure', 'tooling', 'team', 'shout', 'loudly', 'concern', 'infrastructure', 'cluster', 'db', 'networking', 'owned', 'noredink', 'nridoit', 'collab', 'channel', 'doit', 'international', 'partnered', 'provide', 'u', 'debugging', 'consulting', 'leave', 'message', 'probably', 'instructed', 'open', 'ticket', 'median', 'ticket', 'response', 'time', 'minute', 'content', 'creation', 'service', 'documented', 'userfacing', 'request', 'path', 'github', 'admin', 'right', 'noredink', 'computer', 'helpy', 'club', 'admin', 'right', 'main', 'noredink', 'repo', 'need', 'admin', 'right', 'part', 'firefighting', 'response', 'may', 'login', 'github', 'noredinkfirefighter', 'find', 'credential', 'password', 'table', 'content', 'frequent', 'firefighting', 'measure', 'production', 'env', 'basic', 'info', 'demo', 'env', 'info', 'investigating', 'server', 'database', 'investigating', 'application', 'behavior', 'deploying', 'fixing', 'frequent', 'firefighting', 'measure', 'debugging', 'database', 'performance', 'issue', 'monolith', 'tell', 'summary', 'newrelic', 'show', 'mysql', 'taking', 'unusual', 'slice', 'transaction', 'time', 'likely', 'db', 'performance', 'issue', 'database', 'tab', 'newrelic', 'help', 'identify', 'source', 'slowness', 'trace', 'back', 'transaction', 'aws', 'console', 'rds', 'performance', 'insight', 'show', 'active', 'query', 'query', 'state', 'precision', 'show', 'processlist', 'show', 'full', 'processlist', 'sequel', 'pro', 'help', 'spot', 'stuck', 'query', 'running', 'long', 'kill', 'call', 'mysqlrds_kill', 'id', 'http', 'docsawsamazoncomamazonrdslatestuserguideappendixmysqlcommondbataskshtml', 'appendixmysqlcommondbataskskill', 'database', 'cpu', 'try', 'slowing', 'quiz', 'engine', 'usually', 'biggest', 'source', 'db', 'time', 'consumption', 'try', 'spinning', 'monolith', 'server', 'cause', 'request', 'queuing', 'lower', 'throughput', 'database', 'request', 'queueing', 'already', 'high', 'try', 'spinning', 'monolith', 'server', 'absorb', 'request', 'queueing', 'haskell', 'quiz', 'engine', 'problem', 'tell', 'web', 'external', 'super', 'high', 'external', 'service', 'tab', 'show', 'hqe', 'slowest', 'average', 'response', 'time', 'usually', 'time', 'consuming', 'volume', 'traffic', 'disable', 'hqe', 'feature', 'flag', 'safer', 'check', 'hqe', 'firefighting', 'note', 'fighting', 'ddos', 'attack', 'tell', 'unusual', 'bump', 'traffic', 'see', 'throughput', 'chart', 'summary', 'page', 'newrelic', 'usually', 'simplistic', 'hit', 'one', 'endpoint', 'see', 'transaction', 'newrelic', 'open', 'zooming', 'around', 'traffic', 'bump', 'sorting', 'transaction', 'throughput', 'also', 'help', 'spot', 'log', 'cloudflare', 'cred', 'pw', 'select', 'website', 'noredinkcom', 'website', 'going', 'yes', 'click', 'attack', 'mode', 'quick', 'action', 'pane', 'right', 'cause', 'user', 'challenged', 'prove', 'human', 'trying', 'access', 'website', 'including', 'loggedin', 'user', 'might', 'break', 'frontend', 'user', 'get', 'response', 'code', 'html', 'challenge', 'page', 'might', 'break', 'ajax', 'request', 'user', 'already', 'logged', 'middle', 'flow', 'ajax', 'request', 'work', 'handle', 'response', 'unclear', 'much', 'site', 'still', 'covered', 'let', 'support', 'know', 'expect', 'wait', 'min', 'h', 'try', 'turning', 'watch', 'block', 'count', 'firewall', 'event', 'see', 'whether', 'attack', 'still', 'ongoing', 'slow', 'enough', 'frustrate', 'user', 'try', 'identify', 'route', 'hit', 'using', 'newrelic', 'transaction', 'tab', 'add', 'rate', 'limiting', 'rule', 'one', 'route', 'judging', 'would', 'least', 'disruptive', 'user', 'advice', 'fight', 'k', 'rpm', 'ddos', 'attack', 'low', 'request', 'per', 'minute', 'limit', 'attack', 'use', 'high', 'number', 'bot', 'making', 'sparse', 'request', 'still', 'disrupt', 'school', 'school', 'provide', 'internet', 'access', 'single', 'ip', 'address', 'single', 'class', 'student', 'starting', 'class', 'easily', 'hit', 'rate', 'limit', 'let', 'support', 'know', 'expect', 'high', 'throughput', 'watch', 'closely', 'wait', 'ddos', 'measure', 'disrupt', 'user', 'experience', 'worth', 'case', 'production', 'basic', 'info', 'key', 'activity', 'cause', 'significant', 'user', 'pain', 'broken', 'prod', 'ie', 'service', 'consider', 'broken', 'prod', 'causing', 'widespread', 'user', 'pain', 'architecture', 'overview', 'get', 'help', 'monolith', 'teacher', 'assign', 'work', 'view', 'data', 'student', 'answer', 'quiz', 'engine', 'question', 'go', 'writing', 'assignment', 'sign', 'log', 'teacher', 'assign', 'work', 'view', 'data', 'student', 'answer', 'quiz', 'engine', 'question', 'go', 'writing', 'assignment', 'sign', 'log', 'link', 'deploy', 'process', 'overview', 'environmentspecific', 'quirk', 'curriculum', 'action', 'break', 'thing', 'report', 'adminschools', 'route', 'becomes', 'unavailable', 'zamboni', 'planning', 'address', 'part', 'story', 'noncached', 'section', 'premium', 'report', 'grab', 'data', 'service', 'may', 'available', 'account', 'executive', 'unable', 'prepare', 'daily', 'sale', 'call', 'free', 'usage', 'report', 'broken', 'reportsservicedbproductiondb', 'inaccessible', 'fire', 'question_usages', 'inaccessible', 'link', 'slack', 'askteamzen', 'cleversync', 'biggest', 'pain', 'sync', 'failure', 'user', 'initially', 'added', 'user', 'activated', 'clever', 'logged', 'want', 'content', 'date', 'course', 'present', 'missing', 'student', 'clever', 'class', 'roster', 'syncing', 'least', 'hour', 'link', 'slack', 'askteamzen', 'tutorial', 'student', 'see', 'tutorial', 'tutorial', 'service', 'blocked', 'tutorial', 'skipped', 'na', 'student', 'skip', 'tuts', 'service', 'tbd', 'slack', 'team', 'foxen', 'draft', 'student', 'blocked', 'working', 'guided', 'draft', 'self', 'review', 'student', 'blocked', 'seeing', 'previous', 'result', 'guided', 'draft', 'self', 'review', 'teacher', 'blocked', 'grading', 'viewing', 'result', 'guided', 'draft', 'self', 'review', 'student', 'unable', 'save', 'writing', 'teacher', 'unable', 'load', 'writing', 'unable', 'load', 'title', 'class', 'result', 'page', 'fine', 'teacher', 'load', 'rest', 'page', 'ℹ', 'draft', 'service', 'firefighting', 'note', 'draft', 'service', 'firefighting', 'note', 'slack', 'team', 'r', 'avenroost', 'rostering', 'teacher', 'able', 'refer', 'noredink', 'others', 'teacher', 'able', 'browse', 'content', 'standard', 'test', 'curriculumstandards', 'coming', 'soon', 'teacher', 'able', 'browse', 'curriculumplanningdiagnostic', 'premades', 'critical', 'teacher', 'add', 'referral', 'though', 'escalated', 'kraken', 'also', 'critical', 'teacher', 'able', 'browse', 'content', 'standard', 'test', 'able', 'access', 'planning', 'diagnostic', 'premades', 'escalate', 'kraken', 'ℹ', 'rostering', 'service', 'standard', 'v', 'documentation', 'coming', 'soon', 'planning', 'diagnostic', 'premades', 'documentation', 'haskell', 'service', 'playbook', 'slack', 'teamkraken', 'slack', 'teampuffin', 'quizengine', 'http', 'student', 'able', 'quiz', 'student', 'able', 'quiz', 'quiz', 'result', 'page', 'loading', 'readmemd', 'curriculum', 'action', 'break', 'thing', 'monitoring', 'resource', 'slack', 'teampufferfish', 'demo', 'info', 'see', 'demo', 'script', 'qa', 'demo', 'site', 'used', 'partnership', 'consider', 'broken', 'demo', 'set', 'demo', 'monolith', 'tbd', 'dedicated', 'service', 'report', 'section', 'mock', 'school', 'district', 'premium', 'report', 'displaying', 'data', 'otherwise', 'viewable', 'mocked', 'monolith', 'cleversync', 'unless', 'district', 'using', 'bts', 'prep', 'district', 'using', 'demo', 'cleversync', 'bts', 'prep', 'yes', 'following', 'need', 'working', 'filled', 'updated', 'district', 'start', 'using', 'demo', 'bts', 'prep', 'dedicated', 'service', 'tutorial', 'tbd', 'point', 'production', 'service', 'draft', 'loading', 'student', 'full', 'essay', 'view', 'working', 'dedicated', 'service', 'rostering', 'tbd', 'feature', 'disabled', 'quizengine', 'quiz', 'engine', 'view', 'loading', 'dedicated', 'service', 'investigating', 'server', 'database', 'see', 'current', 'state', 'specific', 'infrastructure', 'piece', 'check', 'connectivity', 'database', 'etc', 'check', 'database', 'availability', 'monitoring', 'monolith', 'cloudwatch', 'cover', 'pretty', 'much', 'everything', 'new', 'relic', 'plugins', 'load', 'balancer', 'database', 'redis', 'sendgrid', 'easier', 'correlate', 'apm', 'cloudwatch', 'datadog', 'infrastructure', 'list', 'ec', 'instance', 'load', 'balancer', 'healthcheck', 'url', 'check', 'web', 'app', 'database', 'aws', 'console', 'prod', 'datadog', 'dash', 'prod', 'aws', 'console', 'demo', 'datadog', 'dash', 'demo', 'report', 'cloudwatch', 'datadog', 'infrastructure', 'list', 'ec', 'instance', 'db', 'load', 'balancer', 'healthcheck', 'url', 'check', 'webapp', 'cleversync', 'cloudwatch', 'healthcheck', 'url', 'check', 'webapp', 'contentcreation', 'healthcheck', 'url', 'check', 'auth', 'bugsnag', 'monolith', 'mysql', 'newrelic', 'postgres', 'production', 'staging', 'tutorial', 'cloudwatch', 'datadog', 'haskell', 'service', 'kubernetes', 'look', 'saved', 'view', 'kubernetes', 'node', 'overview', 'kubernetes', 'pod', 'overview', 'healthcheck', 'url', 'check', 'webapp', 'database', 'monolith', 'auth', 'api', 'rollbar', 'production', 'backyard', 'draft', 'cloudwatch', 'datadog', 'haskell', 'service', 'kubernetes', 'look', 'saved', 'view', 'kubernetes', 'node', 'overview', 'kubernetes', 'pod', 'overview', 'healthcheck', 'url', 'check', 'webapp', 'database', 'production', 'database', 'aws', 'staging', 'database', 'aws', 'rostering', 'cloudwatch', 'healthcheck', 'url', 'check', 'auth', 'mysql', 'postgres', 'production', 'staging', 'quizengine', 'cloudwatch', 'datadog', 'haskell', 'service', 'kubernetes', 'look', 'saved', 'view', 'kubernetes', 'node', 'overview', 'kubernetes', 'pod', 'overview', 'healthcheck', 'url', 'check', 'mysql', 'redis', 'datadog', 'redis', 'cluster', 'us', 'mysql', 'database', 'monolith', 'investigating', 'application', 'behavior', 'drill', 'response', 'time', 'performance', 'bottleneck', 'see', 'detail', 'error', 'happening', 'see', 'application', 'log', 'ssh', 'app', 'server', 'monolith', 'new', 'relic', 'apm', 'rollbar', 'web', 'slack', 'engrollbar', 'new', 'relic', 'apm', 'error', 'analytics', 'may', 'error', 'resque', 'task', 'captured', 'rollbar', 'ssh', 'look', 'inside', 'optnoredinksharedlog', 'granted', 'access', 'part', 'onboarding', 'use', 'scriptserversrb', 'find', 'ip', 'address', 'report', 'new', 'relic', 'apm', 'rollbar', 'web', 'slack', 'engrollbarreports', 'ssh', 'view', 'varlogsyslog', 'grep', 'reports_service', 'http', 'githubcomnoredinkreportsblobmasteriacreports_serviceservice', 'l', 'tunnelsh', 'contentcreation', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'bugsnag', 'web', 'cloudwatch', 'log', 'instruction', 'cleversync', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'rollbar', 'web', 'slack', 'engrollbar', 'clever', 'ssh', 'view', 'varlogsyslog', 'grep', 'clever_sync', 'http', 'githubcomnoredinkcleversyncblobmasteriacclever_syncservice', 'l', 'info', 'tunnelsh', 'tutorial', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'bugsnag', 'web', 'slack', 'engrollbartutorials', 'datadog', 'log', 'debugging', 'live', 'kubernetes', 'draft', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'datadog', 'haskell', 'service', 'kubernetes', 'look', 'saved', 'view', 'draft', 'bugsnag', 'monolith', 'bugsnag', 'search', 'draft', 'item', 'may', 'comprehensive', 'datadog', 'log', 'production', 'staging', 'debugging', 'live', 'kubernetes', 'rostering', 'canvas', 'schoology', 'tech', 'documentation', 'firefighting', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'bugsnag', 'web', 'monolith', 'rollbar', 'item', 'may', 'comprehensive', 'cloudwatch', 'log', 'instruction', 'quizengine', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'bugsnag', 'web', 'debugging', 'live', 'kubernetes', 'log', 'debugging', 'live', 'kubernetes', 'deploying', 'fixing', 'currently', 'deployed', 'revision', 'pr', 'deployed', 'turn', 'service', 'change', 'configuration', 'environment', 'variable', 'deploy', 'hotfix', 'safely', 'reboot', 'instance', 'without', 'causing', 'user', 'pain', 'data', 'loss', 'etc', 'monolith', 'quick', 'tip', 'production', 'http', 'githubcomnoredinknoredinkcommitsproduction', 'branch', 'accurate', 'optnoredinkcurrentrevision', 'app', 'server', 'search', 'pr', 'number', 'branch', 'name', 'engnotifyinfo', 'demo', 'search', 'demostatus', 'maintenance', 'mode', 'throttle', 'request', 'quiz', 'engine', 'flipper', 'various', 'feature', 'flag', 'named', 'killswitch', 'turn', 'particular', 'feature', 'follow', 'wiki', 'page', 'adding', 'env', 'var', 'pinch', 'update', 'ssm', 'param', 'awscli', 'propagate', 'change', 'following', 'subsequent', 'step', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'debugging', 'live', 'kubernetes', 'restartingapod', 'debugging', 'live', 'kubernetes', 'safelyrebootaninstance', 'report', 'edeliver', 'ssh', 'completely', 'stop', 'service', 'follow', 'doc', 'deploy', 'step', 'stop', 'instruction', 'stop', 'start', 'restart', 'ssh', 'instruction', 'homewebreports_servicebinreports_service', 'ping', 'return', 'pong', 'instance', 'navigate', 'http', 'wwwnoredinkcomadminschoolsreport', 'verify', 'service', 'returning', 'data', 'contentcreation', 'quick', 'tip', 'deployed', 'branch', 'accurate', 'homewebrevision', 'app', 'server', 'flip', 'content_creation_killswitch', 'http', 'stagingnoredinkcomadminflipperfeaturescontent_creation_killswitch', 'follow', 'howto', 'doc', 'codedeploybased', 'project', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'debugging', 'live', 'kubernetes', 'restartingapod', 'debugging', 'live', 'kubernetes', 'safelyrebootaninstance', 'cleversync', 'edeliver', 'ssh', 'completely', 'stop', 'service', 'follow', 'howto', 'doc', 'deploy', 'step', 'ssh', 'instruction', 'homewebclever_syncbinclever_sync', 'restart', 'homewebclever_syncbinclever_sync', 'ping', 'return', 'pong', 'instance', 'tutorial', 'quick', 'tip', 'deployedtutorialsproduction', 'http', 'githubcomnoredinknoredinkcommitsdeployedtutorialsproduction', 'branch', 'accurate', 'debugging', 'live', 'kubernetes', 'getdeployment', 'syaml', 'grep', 'image', 'image', 'tag', 'suffixed', 'git', 'hash', 'flip', 'tutorials_service_killswitch', 'killswitch', 'follow', 'howto', 'doc', 'kubernetesbased', 'project', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'debugging', 'live', 'kubernetes', 'restartingapod', 'debugging', 'live', 'kubernetes', 'safelyrebootaninstance', 'draft', 'quick', 'tip', 'deployeddraftsproduction', 'http', 'githubcomnoredinknoredinkcommitsdeployeddraftsproduction', 'branch', 'accurate', 'debugging', 'live', 'kubernetes', 'getdeployment', 'syaml', 'grep', 'image', 'image', 'tag', 'suffixed', 'git', 'hash', 'kill', 'switch', 'drafts_service_killswitch', 'use', 'firefighting', 'scenario', 'traffic', 'must', 'cut', 'draft', 'service', 'monolith', 'handle', 'kill', 'switch', 'gracefully', 'show', 'nice', 'error', 'message', 'user', 'follow', 'howto', 'doc', 'codedeploybased', 'project', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'debugging', 'live', 'kubernetes', 'restartingapod', 'debugging', 'live', 'kubernetes', 'safelyrebootaninstance', 'rostering', 'quick', 'tip', 'deployedrosteringproduction', 'http', 'githubcomnoredinknoredinkcommitsdeployedrosteringproduction', 'branch', 'accurate', 'homewebrevision', 'app', 'server', 'rostering', 'service', 'killswitch', 'r', 'eferrals', '_service_killswitch', 'customerio', 'request', 'rostering', 'service', 'r', 'eferrals', '_service_customerio_sleepswitch', 'curriculumstandards', 'killswitch', 'standards_service_killswitch', 'curriculumplanningdiagnostic', 'premades', 'killswitch', 'quiz_engine_premades_service_killswitch', 'follow', 'howto', 'doc', 'codedeploybased', 'project', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'debugging', 'live', 'kubernetes', 'restartingapod', 'debugging', 'live', 'kubernetes', 'safelyrebootaninstance', 'quizengine', 'quick', 'tip', 'deployed', 'http', 'githubcomnoredinknoredinkcommitsdeployedquizenginehttpproduction', 'quizenginehttp', 'http', 'githubcomnoredinknoredinkcommitsdeployedquizenginehttpproduction', 'production', 'http', 'githubcomnoredinknoredinkcommitsdeployedquizenginehttpproduction', 'branch', 'accurate', 'debugging', 'live', 'kubernetes', 'getdeployment', 'syaml', 'grep', 'image', 'image', 'tag', 'suffixed', 'git', 'hash', 'check', 'firefighting', 'header', 'readme', 'follow', 'howto', 'doc', 'kubernetesbased', 'project', 'check', 'firefighting', 'header', 'readme', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'debugging', 'live', 'kubernetes', 'restartingapod', 'debugging', 'live', 'kubernetes', 'safelyrebootaninstance', 'list', 'service', 'copy', 'pasting', 'monolith', 'report', 'contentcreation', 'cleversync', 'tutorial', 'draft', 'rostering', 'quizengine', 'table', 'tentatively', 'retired', 'due', 'suspicion', 'become', 'big', 'useful', 'monolith', 'report', 'cleversync', 'tutorial', 'draft', 'rostering', 'key', 'activity', 'cause', 'significant', 'user', 'pain', 'broken', 'prod', 'teacher', 'assign', 'work', 'view', 'data', 'student', 'answer', 'quiz', 'engine', 'question', 'go', 'writing', 'assignment', 'sign', 'log', 'adminschools', 'route', 'becomes', 'unavailable', 'zamboni', 'planning', 'address', 'part', 'story', 'noncached', 'section', 'premium', 'report', 'grab', 'data', 'service', 'may', 'available', 'biggest', 'pain', 'sync', 'failure', 'user', 'initially', 'added', 'user', 'activated', 'clever', 'logged', 'want', 'content', 'date', 'course', 'present', 'missing', 'student', 'student', 'see', 'tutorial', 'tutorial', 'service', 'blocked', 'tutorial', 'skipped', 'student', 'blocked', 'working', 'guided', 'draft', 'self', 'review', 'student', 'blocked', 'seeing', 'previous', 'result', 'guided', 'draft', 'self', 'review', 'teacher', 'blocked', 'grading', 'viewing', 'result', 'guided', 'draft', 'self', 'review', 'teacher', 'able', 'refer', 'noredink', 'others', 'consider', 'broken', 'prod', 'teacher', 'assign', 'work', 'view', 'data', 'student', 'answer', 'quiz', 'engine', 'question', 'go', 'writing', 'assignment', 'sign', 'log', 'yes', 'yes', 'na', 'student', 'skip', 'tuts', 'service', 'tbd', 'tbd', 'consider', 'broken', 'demo', 'tbd', 'na', 'unless', 'district', 'using', 'bts', 'prep', 'tbd', 'tbd', 'na', 'feature', 'disabled', 'set', 'demo', 'dedicated', 'service', 'mocked', 'dedicated', 'service', 'separate', 'service', 'dedicated', 'service', 'feature', 'disabled', 'drill', 'response', 'time', 'performance', 'bottleneck', 'new', 'relic', 'apm', 'new', 'relic', 'apm', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'new', 'relic', 'apm', 'datadog', 'dashboard', 'see', 'current', 'state', 'specific', 'infrastructure', 'piece', 'cloudwatch', 'cover', 'pretty', 'much', 'everything', 'new', 'relic', 'plugins', 'load', 'balancer', 'database', 'redis', 'sendgrid', 'easier', 'correlate', 'apm', 'cloudwatch', 'datadog', 'infrastructure', 'list', 'ec', 'instance', 'load', 'balancer', 'cloudwatch', 'datadog', 'infrastructure', 'list', 'ec', 'instance', 'db', 'load', 'balancer', 'cloudwatch', 'cloudwatch', 'cloudwatch', 'cloudwatch', 'check', 'database', 'availability', 'monitoring', 'aws', 'console', 'prod', 'datadog', 'dash', 'prod', 'aws', 'console', 'demo', 'datadog', 'dash', 'demo', 'production', 'database', 'aws', 'staging', 'database', 'aws', 'production', 'staging', 'see', 'detail', 'error', 'happening', 'rollbar', 'web', 'slack', 'engrollbar', 'new', 'relic', 'apm', 'error', 'analytics', 'may', 'error', 'resque', 'task', 'captured', 'rollbar', 'rollbar', 'web', 'slack', 'engrollbarreports', 'rollbar', 'web', 'slack', 'engrollbar', 'clever', 'bugsnag', 'web', 'slack', 'engrollbartutorials', 'draft', 'bugsnag', 'draft', 'rollbar', 'info', 'bugsnag', 'shut', 'point', 'future', 'favor', 'bugsnag', 'monolith', 'rollbar', 'search', 'draft', 'item', 'may', 'comprehensive', 'bugsnag', 'web', 'monolith', 'rollbar', 'item', 'may', 'comprehensive', 'see', 'application', 'log', 'ssh', 'look', 'inside', 'optnoredinksharedlog', 'ssh', 'view', 'varlogsyslog', 'grep', 'reports_service', 'http', 'githubcomnoredinkreportsblobmasteriacreports_serviceservice', 'l', 'ssh', 'view', 'varlogsyslog', 'grep', 'clever_sync', 'http', 'githubcomnoredinkcleversyncblobmasteriacclever_syncservice', 'l', 'info', 'cloudwatch', 'log', 'log', 'written', 'cloudwatch', 'application', 'log', 'access', 'log', 'cloudwatch', 'log', 'ssh', 'app', 'server', 'granted', 'access', 'part', 'onboarding', 'use', 'scriptserversrb', 'find', 'ip', 'address', 'tunnelsh', 'tunnelsh', 'ssh', 'using', 'root', 'ssh', 'key', 'found', 'password', 'detailed', 'instruction', 'ssh', 'using', 'root', 'ssh', 'key', 'found', 'password', 'use', 'aws', 'ui', 'find', 'ip', 'address', 'detailed', 'instruction', 'instruction', 'turn', 'service', 'maintenance', 'mode', 'throttle', 'request', 'quiz', 'engine', 'flipper', 'various', 'feature', 'flag', 'named', 'killswitch', 'turn', 'particular', 'feature', 'edeliver', 'ssh', 'completely', 'stop', 'service', 'edeliver', 'ssh', 'completely', 'stop', 'service', 'flip', 'tutorials_service_killswitch', 'killswitch', 'kill', 'switch', 'drafts_service_killswitch', 'use', 'firefighting', 'scenario', 'traffic', 'must', 'cut', 'draft', 'service', 'monolith', 'handle', 'kill', 'switch', 'gracefully', 'show', 'nice', 'error', 'message', 'user', 'rostering', 'service', 'killswitch', 'rostering_service_killswitch', 'customerio', 'request', 'rostering', 'service', 'rostering_service_customerio_sleepswitch', 'currently', 'deployed', 'revision', 'quick', 'tip', 'production', 'http', 'githubcomnoredinknoredinkcommitsproduction', 'branch', 'accurate', 'optnoredinkcurrentrevision', 'app', 'server', 'quick', 'tip', 'deployedtutorialsproduction', 'http', 'githubcomnoredinknoredinkcommitsdeployedtutorialsproduction', 'branch', 'accurate', 'homewebrevision', 'app', 'server', 'quick', 'tip', 'deployeddraftsproduction', 'http', 'githubcomnoredinknoredinkcommitsdeployeddraftsproduction', 'branch', 'accurate', 'homewebrevision', 'app', 'server', 'quick', 'tip', 'deployedrosteringproduction', 'http', 'githubcomnoredinknoredinkcommitsdeployedrosteringproduction', 'branch', 'accurate', 'homewebrevision', 'app', 'server', 'pr', 'deployed', 'search', 'pr', 'number', 'branch', 'name', 'engnotifyinfo', 'demo', 'search', 'demostatus', 'deploy', 'hotfix', 'real', 'emergency', 'upload', 'directly', 'otherwise', 'follow', 'regular', 'hotfix', 'process', 'deploy', 'step', 'deploy', 'step', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'follow', 'regular', 'haskell', 'monorepo', 'deploy', 'process', 'check', 'connectivity', 'database', 'etc', 'healthcheck', 'url', 'check', 'webapp', 'database', 'healthcheck', 'url', 'check', 'webapp', 'healthcheck', 'url', 'check', 'webapp', 'healthcheck', 'url', 'check', 'webapp', 'database', 'monolith', 'auth', 'api', 'rollbar', 'healthcheck', 'url', 'check', 'webapp', 'database', 'healthcheck', 'url', 'check', 'auth', 'mysql', 'postgres', 'architecture', 'overview', 'link', 'deploy', 'process', 'overview', 'environmentspecific', 'quirk', 'link', 'link', 'tbd', 'ℹ', 'draft', 'service', 'ℹ', 'rostering', 'service', 'get', 'help', 'slack', 'askteamzen', 'slack', 'askteamzen', 'slack', 'teampuffin', 'firefighting', 'note', 'draft', 'service', 'firefighting', 'note', 'slack', 'teamlabradoodle', 'haskell', 'service', 'playbook', 'slack', 'teamink', 'slack', 'teampuffin']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# https://medium.com/intel-tech/four-data-cleaning-techniques-to-improve-large-language-model-llm-performance-77bee9003625\n",
    "\n",
    "text = raw_documents[1].copy().page_content\n",
    "\n",
    "# Tokenization\n",
    "\n",
    "cleaned_tokens = re.sub(r\"[_\\-]\", \" \", text) \n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# noise removal\n",
    "cleaned_tokens = [re.sub(r\"[^\\w\\s]\", \"\", token) for token in tokens]\n",
    "cleaned_tokens = [re.sub(r\"[\\d]\", \"\", token) for token in cleaned_tokens]\n",
    "cleaned_tokens = filter(lambda x: x not in string.punctuation + string.whitespace, cleaned_tokens)\n",
    "# emoji_pattern = re.compile(\"[\"\n",
    "#         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                            \"]+\", flags=re.UNICODE)\n",
    "# text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "# normalization\n",
    "cleaned_tokens = [token.lower() for token in cleaned_tokens]\n",
    "\n",
    "# stopword removal\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "cleaned_tokens = [token for token in cleaned_tokens if token not in stop_words]\n",
    "\n",
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "cleaned_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
    "\n",
    "print(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "print(f\"{result['query']}\\n\")\n",
    "pprint.pp(result['result'])\n",
    "print()\n",
    "\n",
    "pprint.pp([document.metadata['source'] for document in result['source_documents']])\n",
    "# pprint.pp(result['source_documents'][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'responsibility first captain during fire'\n",
      "('The first to acknowledge the incident is designated as the fire captain, who '\n",
      " 'is responsible for managing the response until the incident is closed. Note '\n",
      " 'that the role of captain can be handed off at any time, but that a captain '\n",
      " 'should always be present while the incident is ongoing. The first and '\n",
      " 'foremost objective of this system is to ensure the availability of NoRedInk, '\n",
      " 'enabling its reliable use by teachers and students: Prioritize effectiveness '\n",
      " 'over adherence to process (roles may get blurry in the heat of a fire), and '\n",
      " 'try to maintain a balance between short-term effectiveness (quick response '\n",
      " 'time) and long-term effectiveness (avoid burn out).\\n'\n",
      " '\\n'\n",
      " 'Responsibilities\\n'\n",
      " '\\n'\n",
      " 'On-call people are responsible for off hours work (e.g. nights & weekends):\\n'\n",
      " '\\n'\n",
      " 'being available in the #fires on slack & phone after their normal hours '\n",
      " '(including weekends) & within 2 hours of their computer')\n",
      "('first acknowledge incident designated fire captain responsible managing '\n",
      " 'response until incident closed note role captain handed off at any time '\n",
      " 'captain should always present while incident ongoing first foremost '\n",
      " 'objective system ensure availability noredink enabling reliable use teacher '\n",
      " 'student prioritize effectiveness over adherence process role may get blurry '\n",
      " 'in heat fire try maintain balance between shortterm effectiveness quick '\n",
      " 'response time longterm effectiveness avoid burn out responsibility oncall '\n",
      " 'people responsible off hour work eg night weekend available in fire on slack '\n",
      " 'phone after normal hour including weekend within hour computer')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "# from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "stop_words = {\n",
    "    \"himself\",\n",
    "    \"ve\",\n",
    "    \"their\",\n",
    "    \"ain\",\n",
    "    \"needn\",\n",
    "    \"not\",\n",
    "    \"re\",\n",
    "    \"she's\",\n",
    "    \"did\",\n",
    "    \"yourself\",\n",
    "    \"was\",\n",
    "    \"an\",\n",
    "    \"that'll\",\n",
    "    \"wasn\",\n",
    "    \"to\",\n",
    "    \"hers\",\n",
    "    \"y\",\n",
    "    \"itself\",\n",
    "    \"you're\",\n",
    "    \"you\",\n",
    "    \"how\",\n",
    "    \"your\",\n",
    "    \"m\",\n",
    "    \"but\",\n",
    "    \"ourselves\",\n",
    "    \"him\",\n",
    "    \"o\",\n",
    "    \"a\",\n",
    "    \"me\",\n",
    "    \"as\",\n",
    "    \"his\",\n",
    "    \"our\",\n",
    "    \"isn\",\n",
    "    \"needn't\",\n",
    "    \"weren\",\n",
    "    \"what\",\n",
    "    \"shan\",\n",
    "    \"shan't\",\n",
    "    \"had\",\n",
    "    \"whom\",\n",
    "    \"mightn\",\n",
    "    \"who\",\n",
    "    \"and\",\n",
    "    \"of\",\n",
    "    \"aren't\",\n",
    "    \"i\",\n",
    "    \"some\",\n",
    "    \"isn't\",\n",
    "    \"all\",\n",
    "    \"yourselves\",\n",
    "    \"those\",\n",
    "    \"you'll\",\n",
    "    \"you've\",\n",
    "    \"these\",\n",
    "    \"that\",\n",
    "    \"such\",\n",
    "    \"don\",\n",
    "    \"they\",\n",
    "    \"the\",\n",
    "    \"it's\",\n",
    "    \"is\",\n",
    "    \"why\",\n",
    "    \"just\",\n",
    "    \"can\",\n",
    "    \"theirs\",\n",
    "    \"won\",\n",
    "    \"do\",\n",
    "    \"it\",\n",
    "    \"he\",\n",
    "    \"there\",\n",
    "    \"hadn\",\n",
    "    \"for\",\n",
    "    \"or\",\n",
    "    \"then\",\n",
    "    \"no\",\n",
    "    \"s\",\n",
    "    \"ma\",\n",
    "    \"hadn't\",\n",
    "    \"so\",\n",
    "    \"having\",\n",
    "    \"she\",\n",
    "    \"been\",\n",
    "    \"we\",\n",
    "    \"by\",\n",
    "    \"my\",\n",
    "    \"be\",\n",
    "    \"yours\",\n",
    "    \"ll\",\n",
    "    \"nor\",\n",
    "    \"them\",\n",
    "    \"here\",\n",
    "    \"than\",\n",
    "    \"d\",\n",
    "    \"being\",\n",
    "    \"herself\",\n",
    "    \"this\",\n",
    "    \"very\",\n",
    "    \"too\",\n",
    "    \"both\",\n",
    "    \"don't\",\n",
    "    \"if\",\n",
    "    \"you'd\",\n",
    "    \"themselves\",\n",
    "    \"am\",\n",
    "    \"its\",\n",
    "    \"her\",\n",
    "    \"t\",\n",
    "    \"are\",\n",
    "    \"ours\",\n",
    "    \"myself\",\n",
    "}\n",
    "\n",
    "\n",
    "def pre_embedding_process(text: str) -> str:\n",
    "    # Tokenization\n",
    "    cleaned_tokens = re.sub(r\"[_\\-]\", \" \", text) \n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # noise removal\n",
    "    cleaned_tokens = [re.sub(r\"[^\\w\\s]\", \"\", token) for token in tokens]\n",
    "    cleaned_tokens = [re.sub(r\"[\\d]\", \"\", token) for token in cleaned_tokens]\n",
    "    cleaned_tokens = filter(lambda x: x not in string.punctuation + string.whitespace, cleaned_tokens)\n",
    "\n",
    "    # normalization\n",
    "    cleaned_tokens = [token.lower() for token in cleaned_tokens]\n",
    "\n",
    "    # stopword removal\n",
    "    # stop_words = set(stopwords.words(\"english\"))\n",
    "    cleaned_tokens = [token for token in cleaned_tokens if token not in stop_words]\n",
    "\n",
    "    # lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
    "\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "def preprocess_document(document: Document) -> Document:\n",
    "    document_copy = document.copy()\n",
    "    document_copy.page_content = pre_embedding_process(document.page_content)\n",
    "    return document_copy\n",
    "\n",
    "test_query = \"What are the responsibilities of the First Captain during a fire?\"\n",
    "test_text = \"The first to acknowledge the incident is designated as the fire captain, who is responsible for managing the response until the incident is closed. Note that the role of captain can be handed off at any time, but that a captain should always be present while the incident is ongoing. The first and foremost objective of this system is to ensure the availability of NoRedInk, enabling its reliable use by teachers and students: Prioritize effectiveness over adherence to process (roles may get blurry in the heat of a fire), and try to maintain a balance between short-term effectiveness (quick response time) and long-term effectiveness (avoid burn out).\\n\\nResponsibilities\\n\\nOn-call people are responsible for off hours work (e.g. nights & weekends):\\n\\nbeing available in the #fires on slack & phone after their normal hours (including weekends) & within 2 hours of their computer\"\n",
    "\n",
    "import pprint\n",
    "pprint.pp(pre_embedding_process(test_query))\n",
    "pprint.pp(test_text)\n",
    "pprint.pp(pre_embedding_process(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Coroutine, List, Optional, Sequence, Any\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import TextSplitter\n",
    "\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "\n",
    "from langchain_core.callbacks import AsyncCallbackManagerForRetrieverRun, CallbackManagerForRetrieverRun\n",
    "\n",
    "class ParentDocumentPreprocessRetriever(MultiVectorRetriever):\n",
    "    # Updates langchain.retrievers.ParentDocumentRetriever\n",
    "\n",
    "    child_splitter: TextSplitter\n",
    "    \"\"\"The text splitter to use to create child documents.\"\"\"\n",
    "\n",
    "    \"\"\"The key to use to track the parent id. This will be stored in the\n",
    "    metadata of child documents.\"\"\"\n",
    "    parent_splitter: Optional[TextSplitter] = None\n",
    "    \"\"\"The text splitter to use to create parent documents.\n",
    "    If none, then the parent documents will be the raw documents passed in.\"\"\"\n",
    "\n",
    "    child_metadata_fields: Optional[Sequence[str]] = None\n",
    "    \"\"\"Metadata fields to leave in child documents. If None, leave all parent document \n",
    "        metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    def add_documents(\n",
    "        self,\n",
    "        documents: List[Document],\n",
    "        ids: Optional[List[str]] = None,\n",
    "        add_to_docstore: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"Adds documents to the docstore and vectorstores.\n",
    "\n",
    "        Args:\n",
    "            documents: List of documents to add\n",
    "            ids: Optional list of ids for documents. If provided should be the same\n",
    "                length as the list of documents. Can be provided if parent documents\n",
    "                are already in the document store and you don't want to re-add\n",
    "                to the docstore. If not provided, random UUIDs will be used as\n",
    "                ids.\n",
    "            add_to_docstore: Boolean of whether to add documents to docstore.\n",
    "                This can be false if and only if `ids` are provided. You may want\n",
    "                to set this to False if the documents are already in the docstore\n",
    "                and you don't want to re-add them.\n",
    "        \"\"\"\n",
    "        if self.parent_splitter is not None:\n",
    "            documents = self.parent_splitter.split_documents(documents)\n",
    "        if ids is None:\n",
    "            doc_ids = [str(uuid.uuid4()) for _ in documents]\n",
    "            if not add_to_docstore:\n",
    "                raise ValueError(\n",
    "                    \"If ids are not passed in, `add_to_docstore` MUST be True\"\n",
    "                )\n",
    "        else:\n",
    "            if len(documents) != len(ids):\n",
    "                raise ValueError(\n",
    "                    \"Got uneven list of documents and ids. \"\n",
    "                    \"If `ids` is provided, should be same length as `documents`.\"\n",
    "                )\n",
    "            doc_ids = ids\n",
    "\n",
    "        docs = []\n",
    "        full_docs = []\n",
    "        for i, doc in enumerate(documents):\n",
    "            _id = doc_ids[i]\n",
    "            sub_docs = self.child_splitter.split_documents([doc])\n",
    "            sub_docs = [preprocess_document(doc) for doc in sub_docs]\n",
    "            if self.child_metadata_fields is not None:\n",
    "                for _doc in sub_docs:\n",
    "                    _doc.metadata = {\n",
    "                        k: _doc.metadata[k] for k in self.child_metadata_fields\n",
    "                    }\n",
    "            for _doc in sub_docs:\n",
    "                _doc.metadata[self.id_key] = _id\n",
    "            docs.extend(sub_docs)\n",
    "            full_docs.append((_id, doc))\n",
    "        self.vectorstore.add_documents(docs)\n",
    "        if add_to_docstore:\n",
    "            self.docstore.mset(full_docs)\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        preprocessed_query = pre_embedding_process(query)\n",
    "        print(f\"Processed query: {preprocessed_query}\")\n",
    "        return super(ParentDocumentPreprocessRetriever, self)._get_relevant_documents(preprocessed_query, run_manager=run_manager)\n",
    "\n",
    "    def _aget_relevant_documents(self, query: str, *, run_manager: AsyncCallbackManagerForRetrieverRun) -> Coroutine[Any, Any, List[Document]]:\n",
    "        preprocessed_query = pre_embedding_process(query)\n",
    "        print(f\"Processed query: {preprocessed_query}\")\n",
    "        return super()._aget_relevant_documents(preprocessed_query, run_manager=run_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed query: deal with memory leak in prod\n",
      "# 2016–09–30 Other (~resolved🎉?) Fires\n",
      "\n",
      "Memory leak in prod\n",
      "\n",
      "Update / Tentatively Resolved\n",
      "Appears that the cause was not in the suspect list below (but in the deploy) https://github.com/NoRedInk/NoRedInk/pull/13550 which is now the primary suspect with a fix deployed in https://github.com/NoRedInk/NoRedInk/pull/13703 that thus far appears to have removed network correlated memory spikes.\n",
      "\n",
      "Things we can do\n",
      "\n",
      "Deploy/rollback to production-2016-09-29-0434\n",
      "\n",
      "Revert the suspect PRs\n",
      "\n",
      "Suspect PRs\n",
      "From @Joshua L (sorted by suspicion)\n",
      "\n",
      "[ ] topic code cache rejiggering \n",
      "    - https://github.com/NoRedInk/NoRedInk/pull/13564\n",
      "        - Noah doesn’t know enough to review (but tried his best anyway)\n",
      "        - Removes code plan from practices\n",
      "        - makes a kernel for generating a new random seed from an old one\n",
      "        - Makes code plan a module\n",
      "        - caches a topic id with a user id + code index on every call to next topic code with Resque.redis\n",
      "        - Creates a long sequenece from the random number\n",
      "        - Regenerates that long sequence each time the topic code is called\n",
      "        - Loads distribution_tags from cache into a doubley-nested hash\n",
      "\n",
      "[ ] Record the failing exception instead of \"unprocessable\" or \"blank\"\n",
      "    - https://github.com/NoRedInk/NoRedInk/pull/13662\n",
      "        - Records to rollbar weird answers\n",
      "        - rollbar now sends whole stack trace if we get an error there\n",
      "        - No longer calls strip nor assumes an answer array\n",
      "        - raises exception on invalid json, passing the recieved string up\n",
      "        - The string isn’t shown in rollbar?\n",
      "        - This is suspicious because the string isn’t shown in rollbar, potentially meaning it was huge or something else\n",
      "From store:\n",
      "{'page_content': 'tunneled into prod attempted samplefind_or_create_by quick_write_id student_id reproduced timeout however also tried work samplefind_by quick_write_id find_by work find_or_create_by produce timeout', 'metadata': {'source': '.content/Engineering/Fires/Old_Fires/9-20-2019_-_Quick_Writes_Timeout_Fire.md', 'doc_id': '1fc91c2a-e621-45d9-af4d-3f9e6848135e'}, 'type': 'Document'}\n",
      "{'page_content': 'other resolved fire memory leak in prod update tentatively resolved appears cause in suspect list below in deploy http githubcomnoredinknoredinkpull which now primary suspect with fix deployed in http githubcomnoredinknoredinkpull thus far appears have removed network correlated memory spike', 'metadata': {'source': '.content/Engineering/Fires/Old_Fires/2016–09–30_Other_(~resolved_)_Fires.md', 'doc_id': '2f3b5110-a656-4cef-b998-1b9cfd1af424'}, 'type': 'Document'}\n",
      "{'page_content': 'make code plan module cache topic id with user id code index on every call next topic code with resqueredis creates long sequenece from random number regenerates long sequence each time topic code called load distribution_tags from cache into doubleynested hash', 'metadata': {'source': '.content/Engineering/Fires/Old_Fires/2016–09–30_Other_(~resolved_)_Fires.md', 'doc_id': '2f3b5110-a656-4cef-b998-1b9cfd1af424'}, 'type': 'Document'}\n",
      "{'page_content': 'pst ian point out asset bundle ha version teacher_dashboardjs each with different shas also three sprocketsmanifest file in prodpublicassets on prod staging one manifest contains revision teacher_dashboardjs pst charles leaf call tessa join pst ssh into jenkins master node', 'metadata': {'source': '.content/Engineering/Fires/Old_Fires/Deploy_Fire.md', 'doc_id': '18051d76-9f02-4c94-b591-1084cb17ed55'}, 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from faiss import IndexFlatL2\n",
    "\n",
    "\n",
    "query = QUERIES[0]\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    Language.MARKDOWN,\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=400,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    Language.MARKDOWN,\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "embedding = get_embeddings()\n",
    "# store = FAISS(embedding, IndexFlatL2(0), InMemoryDocstore(), {})\n",
    "store = FAISS.from_documents([raw_documents[0]], core_embeddings_model)\n",
    "retriever = ParentDocumentPreprocessRetriever(\n",
    "    vectorstore=store,\n",
    "    docstore=InMemoryStore(),\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "\n",
    "retriever.add_documents(raw_documents, ids=None)\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "print(retrieved_docs[0].page_content)\n",
    "\n",
    "\n",
    "embedding_vector = core_embeddings_model.embed_query(query)\n",
    "docs = store.similarity_search_with_score_by_vector(embedding_vector, k = 4)\n",
    "\n",
    "print(\"From store:\")\n",
    "for page in docs:\n",
    "  print(page[0].dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='grammar_quiz_questions table retrieved with index distribution_idx mysql extra pas retrieve row in sorted order which cause poor performance sometimes unavoidable speed up query querying only field within index create index includes every field in query including primary key', metadata={'source': '.content/Engineering/Fires/Old_Fires/Oct_11_2018,_100_CPU_Fire.md', 'doc_id': '3e447047-1af2-4850-b475-ea187b56e734'}), Document(page_content='index_topic_usages_on_user_id_and_topic_id speed up query querying only field within index create index includes every field in query including primary key approximately row table were scanned mysql lessonimage find m query time cpm throughput trace from teach assignablescontroller new', metadata={'source': '.content/Engineering/Fires/Old_Fires/Oct_11_2018,_100_CPU_Fire.md', 'doc_id': 'e107665a-5712-4192-881f-38587f7037b9'}), Document(page_content='mysql extra pas retrieve row in sorted order which cause poor performance sometimes unavoidable speed up query querying only field within index create index includes every field in query including primary key approximately row table were scanned', metadata={'source': '.content/Engineering/Fires/Old_Fires/Oct_11_2018,_100_CPU_Fire.md', 'doc_id': 'e107665a-5712-4192-881f-38587f7037b9'}), Document(page_content='mysql extra pas retrieve row in sorted order which cause poor performance sometimes unavoidable speed up query querying only field within index create index includes every field in query including primary key approximately row table were scanned', metadata={'source': '.content/Engineering/Fires/Old_Fires/Oct_11_2018,_100_CPU_Fire.md', 'doc_id': 'e107665a-5712-4192-881f-38587f7037b9'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import RePhraseQueryRetriever\n",
    "\n",
    "retriever_from_llm = RePhraseQueryRetriever.from_llm(\n",
    "    retriever=store.as_retriever(), llm=llm\n",
    ")\n",
    "\n",
    "docs = retriever_from_llm.invoke(\n",
    "    \"Hi I'm Lance. What are the responsibilities of the First Captain during a fire?\"\n",
    ")\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pairwise ranking..\n",
      "[{'id': 0,\n",
      "  'text': 'If the database is at 100% CPU\\n'\n",
      "          'You can try slowing down the quiz engine as it’s usually the '\n",
      "          'biggest source of DB time consumption\\n'\n",
      "          'You can try spinning down a few Monolith servers to cause request '\n",
      "          'queuing and lower throughput to the database\\n'\n",
      "          '\\n'\n",
      "          'If not, and request queueing is already very high, you can try '\n",
      "          'spinning up more Monolith servers to absorb request queueing\\n'\n",
      "          '\\n'\n",
      "          'Haskell Quiz Engine Problems?\\n'\n",
      "          '\\n'\n",
      "          'How to tell?\\n'\n",
      "          '\\n'\n",
      "          'web external is super high\\n'\n",
      "          '\\n'\n",
      "          '“External Services” tab shows that HQE has the “slowest average '\n",
      "          'response time” (it usually is the most time consuming because of '\n",
      "          'volume of traffic).\\n'\n",
      "          '\\n'\n",
      "          'What to do?\\n'\n",
      "          '\\n'\n",
      "          'disable all HQE feature flags (off is safer)\\n'\n",
      "          '\\n'\n",
      "          'check in on HQE firefighting notes\\n'\n",
      "          '\\n'\n",
      "          'Fighting a DDoS attack\\n'\n",
      "          '\\n'\n",
      "          'How to tell?\\n'\n",
      "          '\\n'\n",
      "          'An unusual bump in traffic (see the Throughput  chart in the '\n",
      "          'Summary page in NewRelic)',\n",
      "  'meta': {'source': '.content/Engineering/Fires/Firefighting_Resources.md'},\n",
      "  'score': 0.718839168548584},\n",
      " {'id': 2,\n",
      "  'text': 'Databases\\n'\n",
      "          '\\n'\n",
      "          'Check if any DB operations are spiking\\n'\n",
      "          'You can click ActiveRecord or MySQL on the top left to see more '\n",
      "          'activerecord/mysql queries in the graph, if nothing is spiking\\n'\n",
      "          'Sometimes everything is spiking, or lots of things are, and in '\n",
      "          'these cases it’s more likely a general MySQL problem\\n'\n",
      "          '➡️ Diagnose further on RDS Performance Insights\\n'\n",
      "          '\\n'\n",
      "          'Click on the spiky operation\\n'\n",
      "          '\\n'\n",
      "          'Datadog\\n'\n",
      "          '\\n'\n",
      "          'Datadog\\n'\n",
      "          '\\n'\n",
      "          'Two main things here:\\n'\n",
      "          '\\n'\n",
      "          'Haskell in Kubernetes Dashboard\\n'\n",
      "          'A dashboard with 90% of what you need to triage fires in Haskell '\n",
      "          'services deployed to Kubernetes\\n'\n",
      "          '\\n'\n",
      "          'Process Monitor\\n'\n",
      "          'Like htop, but in Datadog. Useful for seeing Threads per process '\n",
      "          'and what % a process is taking over the entire machine.\\n'\n",
      "          '\\n'\n",
      "          'Haskell in Kubernetes Dashboard\\n'\n",
      "          '\\n'\n",
      "          '🔗 Link\\n'\n",
      "          '\\n'\n",
      "          'Is CPU usage in the monolith too high? Above 48% is too high.\\n'\n",
      "          '\\n'\n",
      "          'Is load average for Kubernetes too high?\\n'\n",
      "          'ℹ️ It might indicate contention in one or more services\\n'\n",
      "          'ℹ️ If it correlates with IOWait spikes, it might indicate '\n",
      "          'network/disk contention',\n",
      "  'meta': {'source': '.content/Engineering/Fires/Fire_triage_drill.md'},\n",
      "  'score': 0.009271880611777306},\n",
      " {'id': 1,\n",
      "  'text': 'Throughput\\n'\n",
      "          'Do we have a huge spike in throughput? 200k RPM and above might '\n",
      "          'mean we’re under a DDoS attack\\n'\n",
      "          '➡️ Check out what to do here: +Firefighting Resources: '\n",
      "          'Fighting-a-DDoS-attack\\n'\n",
      "          '\\n'\n",
      "          'Error rate\\n'\n",
      "          'Are error spiking? Like 1% or more\\n'\n",
      "          '➡️ Go to Errors tab\\n'\n",
      "          '➡️ Check out Bugsnag (finer grained timeline)\\n'\n",
      "          '\\n'\n",
      "          'External Services\\n'\n",
      "          '\\n'\n",
      "          'Services by total response time\\n'\n",
      "          'Any service started taking a longer time than usual?\\n'\n",
      "          'A Haskell service?\\n'\n",
      "          '➡️ Go to the specific service’s dashboard in NewRelic and do a '\n",
      "          'similar analysis there (what made it slow? etc)\\n'\n",
      "          '➡️ Also, open the Haskell Services in Kubernete dashboard in '\n",
      "          'Datadog, because Kubernetes might be at fault\\n'\n",
      "          'What services are in Kubernetes?\\n'\n",
      "          'Drafts\\n'\n",
      "          'Quiz Engine\\n'\n",
      "          'Tutorials',\n",
      "  'meta': {'source': '.content/Engineering/Fires/Fire_triage_drill.md'},\n",
      "  'score': 0.0045306808315217495},\n",
      " {'id': 4,\n",
      "  'text': '3:10 Uh oh! We deploy Haskell services before we start the demo '\n",
      "          'deploy. During that period, \\n'\n",
      "          '(a) services and the monolith are out of sync \\n'\n",
      "          '(b) the demo account pool is wiped\\n'\n",
      "          'Suggestion from Tessa: we might turn on the drafts service '\n",
      "          'killswitch and the hypothetical HQE killswitch before the deploy, '\n",
      "          'so that the bits of the site that we expect to have broken are '\n",
      "          'explicitly down.\\n'\n",
      "          '\\n'\n",
      "          'Kristine: there’s an agreement with CS to not use demo during this '\n",
      "          'period, so it’s not necessary.\\n'\n",
      "          '\\n'\n",
      "          'Tessa, editorializing: Kind of interesting to have a 2-hour extreme '\n",
      "          'version of our usual production deploy problems! I wonder if Foxen '\n",
      "          'are aware of the situation 🤔',\n",
      "  'meta': {'source': '.content/Engineering/Fires/Old_Fires/Fire_Dec_8,_2020_-_Demo_deploy_stuck.md'},\n",
      "  'score': 0.000754026579670608},\n",
      " {'id': 3,\n",
      "  'text': 'Takeaways\\n'\n",
      "          '\\n'\n",
      "          'RSS feed for Canvas API changes could directly create new Linear '\n",
      "          'issues\\n'\n",
      "          'There was an update about this API change: '\n",
      "          'https://community.canvaslms.com/t5/Canvas-Change-Log/Canvas-Platform-Breaking-Changes/ta-p/262015 '\n",
      "          '— \"These numerical variable substitutions will be deprecated and '\n",
      "          'changed to string values on 2022-10-15\"\\n'\n",
      "          'Did someone at NRI receive an email alert about this from Canvas? '\n",
      "          'Where did it get sent to and why didn’t anyone see it?\\n'\n",
      "          'Slack integration is /feed to add an RSS feed to a slack channel\\n'\n",
      "          '\\n'\n",
      "          'Haskell deploy quite slow, ideally should be under 20 minutes\\n'\n",
      "          'And very common to need to retry Haskell deploy at least one more '\n",
      "          'time before it works\\n'\n",
      "          '\\n'\n",
      "          'Should be able to deploy to any Haskell services without it hanging '\n",
      "          'on tests if during a fire!',\n",
      "  'meta': {'source': '.content/Engineering/Fires/Old_Fires/2022-10-17_Canvas_API_breaks_assignments.md'},\n",
      "  'score': 0.0004180898249614984},\n",
      " {'id': 5,\n",
      "  'text': '[ ] Currently deployed revision When was a PR deployed? Turn off '\n",
      "          'the service Change configuration / environment variable Deploy a '\n",
      "          'hotfix Safely reboot an instance (without causing user pain / data '\n",
      "          'loss / etc) Monolith Quick: Tip of the '\n",
      "          '[production](https://github.com/NoRedInk/NoRedInk/commits/production) '\n",
      "          'branch Most accurate: /opt/noredink/current/REVISION of any app '\n",
      "          'server Search for the PR number or branch name in #eng-notify-info '\n",
      "          'For demo, search in #demo-status - maintenance mode - throttle '\n",
      "          'requests to the quiz engine - flipper has various feature flags '\n",
      "          'named *killswitch* that turns off a particular feature Follow the '\n",
      "          'wiki page for adding an env var. In a pinch, update the SSM param '\n",
      "          'with awscli and propagate the change following the subsequent '\n",
      "          'steps. Follow the regular Haskell Monorepo deploy process '\n",
      "          '+Debugging live on Kubernetes: Restarting-a-pod +Debugging live on '\n",
      "          'Kubernetes: Safely-reboot-an-instance Reports edeliver or ssh to '\n",
      "          'completely stop the service Follow this doc Deploy',\n",
      "  'meta': {'source': '.content/Engineering/Fires/Firefighting_Resources.md'},\n",
      "  'score': 0.00016891588165890425}]\n"
     ]
    }
   ],
   "source": [
    "from flashrank import Ranker, RerankRequest\n",
    "from random import shuffle\n",
    "# Nano (~4MB), blazing fast model & competitive performance (ranking precision).\n",
    "ranker = Ranker()\n",
    "\n",
    "query = \"What should I do if there are problems with the haskell quiz engine?\"\n",
    "passages = [\n",
    "    {\n",
    "        \"id\": 0,\n",
    "        \"text\": \"If the database is at 100% CPU\\nYou can try slowing down the quiz engine as it’s usually the biggest source of DB time consumption\\nYou can try spinning down a few Monolith servers to cause request queuing and lower throughput to the database\\n\\nIf not, and request queueing is already very high, you can try spinning up more Monolith servers to absorb request queueing\\n\\nHaskell Quiz Engine Problems?\\n\\nHow to tell?\\n\\nweb external is super high\\n\\n“External Services” tab shows that HQE has the “slowest average response time” (it usually is the most time consuming because of volume of traffic).\\n\\nWhat to do?\\n\\ndisable all HQE feature flags (off is safer)\\n\\ncheck in on HQE firefighting notes\\n\\nFighting a DDoS attack\\n\\nHow to tell?\\n\\nAn unusual bump in traffic (see the Throughput  chart in the Summary page in NewRelic)\",\n",
    "        \"meta\": {\"source\": \".content/Engineering/Fires/Firefighting_Resources.md\"},\n",
    "    },\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"text\": \"Throughput\\nDo we have a huge spike in throughput? 200k RPM and above might mean we’re under a DDoS attack\\n➡️ Check out what to do here: +Firefighting Resources: Fighting-a-DDoS-attack\\n\\nError rate\\nAre error spiking? Like 1% or more\\n➡️ Go to Errors tab\\n➡️ Check out Bugsnag (finer grained timeline)\\n\\nExternal Services\\n\\nServices by total response time\\nAny service started taking a longer time than usual?\\nA Haskell service?\\n➡️ Go to the specific service’s dashboard in NewRelic and do a similar analysis there (what made it slow? etc)\\n➡️ Also, open the Haskell Services in Kubernete dashboard in Datadog, because Kubernetes might be at fault\\nWhat services are in Kubernetes?\\nDrafts\\nQuiz Engine\\nTutorials\",\n",
    "        \"meta\": {\"source\": \".content/Engineering/Fires/Fire_triage_drill.md\"},\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"text\": \"Databases\\n\\nCheck if any DB operations are spiking\\nYou can click ActiveRecord or MySQL on the top left to see more activerecord/mysql queries in the graph, if nothing is spiking\\nSometimes everything is spiking, or lots of things are, and in these cases it’s more likely a general MySQL problem\\n➡️ Diagnose further on RDS Performance Insights\\n\\nClick on the spiky operation\\n\\nDatadog\\n\\nDatadog\\n\\nTwo main things here:\\n\\nHaskell in Kubernetes Dashboard\\nA dashboard with 90% of what you need to triage fires in Haskell services deployed to Kubernetes\\n\\nProcess Monitor\\nLike htop, but in Datadog. Useful for seeing Threads per process and what % a process is taking over the entire machine.\\n\\nHaskell in Kubernetes Dashboard\\n\\n🔗 Link\\n\\nIs CPU usage in the monolith too high? Above 48% is too high.\\n\\nIs load average for Kubernetes too high?\\nℹ️ It might indicate contention in one or more services\\nℹ️ If it correlates with IOWait spikes, it might indicate network/disk contention\",\n",
    "        \"meta\": {\"source\": \".content/Engineering/Fires/Fire_triage_drill.md\"},\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"text\": 'Takeaways\\n\\nRSS feed for Canvas API changes could directly create new Linear issues\\nThere was an update about this API change: https://community.canvaslms.com/t5/Canvas-Change-Log/Canvas-Platform-Breaking-Changes/ta-p/262015 — \"These numerical variable substitutions will be deprecated and changed to string values on 2022-10-15\"\\nDid someone at NRI receive an email alert about this from Canvas? Where did it get sent to and why didn’t anyone see it?\\nSlack integration is /feed to add an RSS feed to a slack channel\\n\\nHaskell deploy quite slow, ideally should be under 20 minutes\\nAnd very common to need to retry Haskell deploy at least one more time before it works\\n\\nShould be able to deploy to any Haskell services without it hanging on tests if during a fire!',\n",
    "        \"meta\": {\n",
    "            \"source\": \".content/Engineering/Fires/Old_Fires/2022-10-17_Canvas_API_breaks_assignments.md\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"text\": \"3:10 Uh oh! We deploy Haskell services before we start the demo deploy. During that period, \\n(a) services and the monolith are out of sync \\n(b) the demo account pool is wiped\\nSuggestion from Tessa: we might turn on the drafts service killswitch and the hypothetical HQE killswitch before the deploy, so that the bits of the site that we expect to have broken are explicitly down.\\n\\nKristine: there’s an agreement with CS to not use demo during this period, so it’s not necessary.\\n\\nTessa, editorializing: Kind of interesting to have a 2-hour extreme version of our usual production deploy problems! I wonder if Foxen are aware of the situation 🤔\",\n",
    "        \"meta\": {\n",
    "            \"source\": \".content/Engineering/Fires/Old_Fires/Fire_Dec_8,_2020_-_Demo_deploy_stuck.md\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"text\": \"[ ] Currently deployed revision When was a PR deployed? Turn off the service Change configuration / environment variable Deploy a hotfix Safely reboot an instance (without causing user pain / data loss / etc) Monolith Quick: Tip of the [production](https://github.com/NoRedInk/NoRedInk/commits/production) branch Most accurate: /opt/noredink/current/REVISION of any app server Search for the PR number or branch name in #eng-notify-info For demo, search in #demo-status - maintenance mode - throttle requests to the quiz engine - flipper has various feature flags named *killswitch* that turns off a particular feature Follow the wiki page for adding an env var. In a pinch, update the SSM param with awscli and propagate the change following the subsequent steps. Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance Reports edeliver or ssh to completely stop the service Follow this doc Deploy\",\n",
    "        \"meta\": {\"source\": \".content/Engineering/Fires/Firefighting_Resources.md\"},\n",
    "    },\n",
    "]\n",
    "# passages = [\n",
    "#     {\n",
    "#         \"text\": \"If the database is at 100% CPU\\nYou can try slowing down the quiz engine as it’s usually the biggest source of DB time consumption\\nYou can try spinning down a few Monolith servers to cause request queuing and lower throughput to the database\\n\\nIf not, and request queueing is already very high, you can try spinning up more Monolith servers to absorb request queueing\\n\\nHaskell Quiz Engine Problems?\\n\\nHow to tell?\\n\\nweb external is super high\\n\\n“External Services” tab shows that HQE has the “slowest average response time” (it usually is the most time consuming because of volume of traffic).\\n\\nWhat to do?\\n\\ndisable all HQE feature flags (off is safer)\\n\\ncheck in on HQE firefighting notes\\n\\nFighting a DDoS attack\\n\\nHow to tell?\\n\\nAn unusual bump in traffic (see the Throughput  chart in the Summary page in NewRelic)\",\n",
    "#         \"metadata\": {\n",
    "#             \"source\": \".content/Engineering/Fires/Firefighting_Resources.md\"\n",
    "#         },\n",
    "#         \"id\": \"g\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"text\": \"Throughput\\nDo we have a huge spike in throughput? 200k RPM and above might mean we’re under a DDoS attack\\n➡️ Check out what to do here: +Firefighting Resources: Fighting-a-DDoS-attack\\n\\nError rate\\nAre error spiking? Like 1% or more\\n➡️ Go to Errors tab\\n➡️ Check out Bugsnag (finer grained timeline)\\n\\nExternal Services\\n\\nServices by total response time\\nAny service started taking a longer time than usual?\\nA Haskell service?\\n➡️ Go to the specific service’s dashboard in NewRelic and do a similar analysis there (what made it slow? etc)\\n➡️ Also, open the Haskell Services in Kubernete dashboard in Datadog, because Kubernetes might be at fault\\nWhat services are in Kubernetes?\\nDrafts\\nQuiz Engine\\nTutorials\",\n",
    "#         \"metadata\": {\n",
    "#             \"source\": \".content/Engineering/Fires/Fire_triage_drill.md\"\n",
    "#         },\n",
    "#         \"id\": \"d\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"text\": \"Databases\\n\\nCheck if any DB operations are spiking\\nYou can click ActiveRecord or MySQL on the top left to see more activerecord/mysql queries in the graph, if nothing is spiking\\nSometimes everything is spiking, or lots of things are, and in these cases it’s more likely a general MySQL problem\\n➡️ Diagnose further on RDS Performance Insights\\n\\nClick on the spiky operation\\n\\nDatadog\\n\\nDatadog\\n\\nTwo main things here:\\n\\nHaskell in Kubernetes Dashboard\\nA dashboard with 90% of what you need to triage fires in Haskell services deployed to Kubernetes\\n\\nProcess Monitor\\nLike htop, but in Datadog. Useful for seeing Threads per process and what % a process is taking over the entire machine.\\n\\nHaskell in Kubernetes Dashboard\\n\\n🔗 Link\\n\\nIs CPU usage in the monolith too high? Above 48% is too high.\\n\\nIs load average for Kubernetes too high?\\nℹ️ It might indicate contention in one or more services\\nℹ️ If it correlates with IOWait spikes, it might indicate network/disk contention\",\n",
    "#         \"metadata\": {\n",
    "#             \"source\": \".content/Engineering/Fires/Fire_triage_drill.md\"\n",
    "#         },\n",
    "#         \"id\": \"f\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"text\": \"Takeaways\\n\\nRSS feed for Canvas API changes could directly create new Linear issues\\nThere was an update about this API change: https://community.canvaslms.com/t5/Canvas-Change-Log/Canvas-Platform-Breaking-Changes/ta-p/262015 — \\\"These numerical variable substitutions will be deprecated and changed to string values on 2022-10-15\\\"\\nDid someone at NRI receive an email alert about this from Canvas? Where did it get sent to and why didn’t anyone see it?\\nSlack integration is /feed to add an RSS feed to a slack channel\\n\\nHaskell deploy quite slow, ideally should be under 20 minutes\\nAnd very common to need to retry Haskell deploy at least one more time before it works\\n\\nShould be able to deploy to any Haskell services without it hanging on tests if during a fire!\",\n",
    "#         \"metadata\": {\n",
    "#             \"source\": \".content/Engineering/Fires/Old_Fires/2022-10-17_Canvas_API_breaks_assignments.md\"\n",
    "#         },\n",
    "#         \"id\": \"j\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"text\": \"3:10 Uh oh! We deploy Haskell services before we start the demo deploy. During that period, \\n(a) services and the monolith are out of sync \\n(b) the demo account pool is wiped\\nSuggestion from Tessa: we might turn on the drafts service killswitch and the hypothetical HQE killswitch before the deploy, so that the bits of the site that we expect to have broken are explicitly down.\\n\\nKristine: there’s an agreement with CS to not use demo during this period, so it’s not necessary.\\n\\nTessa, editorializing: Kind of interesting to have a 2-hour extreme version of our usual production deploy problems! I wonder if Foxen are aware of the situation 🤔\",\n",
    "#         \"metadata\": {\n",
    "#             \"source\": \".content/Engineering/Fires/Old_Fires/Fire_Dec_8,_2020_-_Demo_deploy_stuck.md\"\n",
    "#         },\n",
    "#         \"id\": \"l\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"text\": \"[ ] Currently deployed revision When was a PR deployed? Turn off the service Change configuration / environment variable Deploy a hotfix Safely reboot an instance (without causing user pain / data loss / etc) Monolith Quick: Tip of the [production](https://github.com/NoRedInk/NoRedInk/commits/production) branch Most accurate: /opt/noredink/current/REVISION of any app server Search for the PR number or branch name in #eng-notify-info For demo, search in #demo-status - maintenance mode - throttle requests to the quiz engine - flipper has various feature flags named *killswitch* that turns off a particular feature Follow the wiki page for adding an env var. In a pinch, update the SSM param with awscli and propagate the change following the subsequent steps. Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance Reports edeliver or ssh to completely stop the service Follow this doc Deploy\",\n",
    "#         \"metadata\": {\n",
    "#             \"source\": \".content/Engineering/Fires/Firefighting_Resources.md\"\n",
    "#         },\n",
    "#         \"id\": \"v\"\n",
    "#     }\n",
    "# ]\n",
    "shuffle(passages)\n",
    "rerankrequest = RerankRequest(query=query, passages=passages)\n",
    "results = ranker.rerank(rerankrequest)\n",
    "\n",
    "import pprint\n",
    "pprint.pp(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"🔥 Fire triage drill\n",
      "\n",
      "Note: This document is not intended to be consumed by itself. I’m personally introducing fire fighters to this drill at the start of their on-call cycle, and the document is here for a) reference for me b) reference for fire fighters after our meeting.\n",
      "\n",
      "The fire drill starts at the NewRelic APM main screen for the Monolith. Go through the numbers on the image, reading their description below, and follow the arrows ➡️ .\n",
      "\n",
      "NewRelic\n",
      "\n",
      "Monolith NewRelic main screen\n",
      "\n",
      "🔗 Link\n",
      "\n",
      "Request breakdown\n",
      "Did something start taking up a larger share of request time?\n",
      "External services\n",
      "➡️ Go to the External Services tab in the right and figure out which service\n",
      "\n",
      "\n",
      "DB\n",
      "➡️ Go to the Databases tab and see whether some transactions started spiking\n",
      "➡️ Open RDS Performance Insights for higher resolution data\n",
      "\n",
      "\n",
      "Queueing or Ruby Slowness\n",
      "➡️ Open Load Balancers Dashboard\n",
      "➡️ Opsworks time-based instances and load-based instances\n",
      "Do we have instances booting up?\n",
      "\n",
      "Throughput\n",
      "Do we have a huge spike in throughput? 200k RPM and above might mean we’re under a DDoS attack\n",
      "➡️ Check out what to do here: +Firefighting Resources: Fighting-a-DDoS-attack\n",
      "\n",
      "Error rate\n",
      "Are error spiking? Like 1% or more\n",
      "➡️ Go to Errors tab\n",
      "➡️ Check out Bugsnag (finer grained timeline)\n",
      "\n",
      "External Services\n",
      "\n",
      "Services by total response time\n",
      "Any service started taking a longer time than usual?\n",
      "A Haskell service?\n",
      "➡️ Go to the specific service’s dashboard in NewRelic and do a similar analysis there (what made it slow? etc)\n",
      "➡️ Also, open the Haskell Services in Kubernete dashboard in Datadog, because Kubernetes might be at fault\n",
      "What services are in Kubernetes?\n",
      "Drafts\n",
      "Quiz Engine\n",
      "Tutorials\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "An Elixir service?\n",
      "➡️ Go to the specific service’s dashboard in NewRelic and do a similar analysis there (what made it slow? etc)\n",
      "🗒️ This never happened. Elixir reacts well to increased load. No Elixir services are set up for horizontal scalability tho, so the only alternative if this happens is:\n",
      "➡️ Increase the instance size (start by looking at the service’s repo, they all have an iac directory with terraform stuff)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Third-party service?\n",
      "Is it bringing the site down?\n",
      "➡️ Check if there’s a killswitch for functionality that talks to this service\n",
      "\n",
      "Click the service to get throughput and response time. If it’s our service, the service’s own NewRelic dashboard will show more details tho.\n",
      "\n",
      "Databases\n",
      "\n",
      "Check if any DB operations are spiking\n",
      "You can click ActiveRecord or MySQL on the top left to see more activerecord/mysql queries in the graph, if nothing is spiking\n",
      "Sometimes everything is spiking, or lots of things are, and in these cases it’s more likely a general MySQL problem\n",
      "➡️ Diagnose further on RDS Performance Insights\n",
      "\n",
      "Click on the spiky operation\n",
      "\n",
      "Datadog\n",
      "\n",
      "Datadog\n",
      "\n",
      "Two main things here:\n",
      "\n",
      "Haskell in Kubernetes Dashboard\n",
      "A dashboard with 90% of what you need to triage fires in Haskell services deployed to Kubernetes\n",
      "\n",
      "Process Monitor\n",
      "Like htop, but in Datadog. Useful for seeing Threads per process and what % a process is taking over the entire machine.\n",
      "\n",
      "Haskell in Kubernetes Dashboard\n",
      "\n",
      "🔗 Link\n",
      "\n",
      "Is CPU usage in the monolith too high? Above 48% is too high.\n",
      "\n",
      "Is load average for Kubernetes too high?\n",
      "ℹ️ It might indicate contention in one or more services\n",
      "ℹ️ If it correlates with IOWait spikes, it might indicate network/disk contention\n",
      "\n",
      "Is memory usage too high? Around 80~90% is too high\n",
      "➡️ Scroll down to Memory usage by container to quickly check if it’s the application you’re browsing\n",
      "➡️ A more in-depth investigation can be done in the Process Monitor\n",
      "\n",
      "Are nodes scaling up?\n",
      "\n",
      "The dotted lines show last week, for comparison.\n",
      "Kubernetes doesn’t scale up on a schedule, rather on-demand, so solid and dotted lines matching is not strictly required.\n",
      "\n",
      "Memory Usage by Container\n",
      "\n",
      "Light orange line: limits.memory in Kubernetes. Once reached, the container gets killed. Kube will re-start the container, but meanwhile, all requests to it will bounce as 5xx.\n",
      "Dark orange line: Haskell RTS Heap limit (-M). Once reached the RTS should self-destruct. Kube will notice and re-start the container, but meanwhile all requests to it will bounce as 5xx.\n",
      "Dark red line: Garbage collector “compaction” threshold. After this threshold the GC will start using compaction and we should observe increased CPU usage and/or increased response time.\n",
      "\n",
      "CPU Usage by Container\n",
      "ℹ️ This chart is passed over a smoothing function to make patterns easier to spot. Values don’t reflect reality, only trends.\n",
      ":tip: This chart makes it easy to spot Pods coming up and going down bc of auto-scaling.\n",
      "Yellow line: requests.cpu in Kubernetes. How much we expect this Pod to use at most.\n",
      "\n",
      "Pod count (desired and actual)\n",
      "Dotted red line: Desired replicas. How many Pods the HorizontalPodAutoscaler thinks we should have based on CPU usage.\n",
      "Solid orange line: Actual replicas. How many Pods the HorizontalPodAutoscaler sees.\n",
      "Light blue area: Pending Pods. How many Pods are scheduled to run in an available node, or a node that’s booting up, but are not yet running.\n",
      "Dark blue area: Running pods. How many Pods are actually running.\n",
      "ℹ️ Pods pending for too long is a problem. They shouldn’t remain in Pending for longer than 3 minutes.\n",
      "ℹ️ Aside from auto-scaling, this changes during blue-green deploys, where we double our fleet.\n",
      "\n",
      "Containers restarted (by Pod)\n",
      "Bumps in this metric represent times a container has restarted inside a Pod.\n",
      "ℹ️ We have an on-going container restart problem in Haskell apps.\n",
      "\n",
      "Process monitor\n",
      "\n",
      "🔗 Link\n",
      "\n",
      "CloudWatch\n",
      "\n",
      "Load Balancers Dashboard\n",
      "\n",
      "🔗 Link\n",
      "\n",
      "RDS Performance Insights\n",
      "\n",
      "🔗 Link\n",
      "\n",
      "Are there any significant spikes in Sessions?\n",
      "➡️ Zoom into the spikes. Performance Insights has per-second resolution, so you’ll see more interesting patterns by zooming in.\n",
      "ℹ️ Spikes above Max vCPU tend to cause contention\n",
      "🗒️ The wait types are related to MySQL Thread State and indicate what were MySQL threads doing, mostly, on average\n",
      "\n",
      "Switch from Slice by wait to Slice by SQL to get a sense of what queries were responsible for congestion\n",
      "\n",
      "By clicking the + sign in the table below you will find samples of the most time-consuming queries with their actual params (truncated, unfortunately).\n",
      "\n",
      "ℹ️ MySQL has been having hiccups on writes, and they manifest like this:\n",
      "\n",
      "They usually last a few seconds and go away. We don’t have a solution nor understand root cause yet.\n",
      "\n",
      "Bugsnag\n",
      "\n",
      "🔗 Link\n",
      "\n",
      "Appendix\n",
      "\n",
      "Who’s gone through the drill?\n",
      "\n",
      "Juan\n",
      "\n",
      "Stöffel\n",
      "\n",
      "Blake\n",
      "\n",
      "Jasper\n",
      "\n",
      "Ally\n",
      "\n",
      "Ian\n",
      "\n",
      "Alex Perkins\n",
      "\n",
      "Richard\n",
      "\n",
      "Tessa\n",
      "\n",
      "Ju\n",
      "\n",
      "Charlie\n",
      "\n",
      "Nuno\n",
      "\n",
      "Juan Wajnerman\n",
      "\n",
      "Who’s missing?\n",
      "\n",
      "Ary\n",
      "\n",
      "Brian C\n",
      "\n",
      "Brian H\n",
      "\n",
      "Glass\n",
      "\n",
      "Mike Steder\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: The summary is a drill report that covers various metrics and issues related to a system. The main topics include:\n",
      "\n",
      "1. Fire triage drill:\n",
      "\t* Haskell RTS Heap limit reached, causing self-destruction.\n",
      "\t* Garbage collector compaction threshold exceeded, leading to increased CPU usage and response time.\n",
      "2. CPU Usage by Container:\n",
      "\t* Yellow line represents expected CPU usage.\n",
      "\t* Dotted red line shows desired replicas (HorizontalPodAutoscaler).\n",
      "\t* Solid orange line shows actual replicas.\n",
      "3. Pod count (desired and actual):\n",
      "\t* Light blue area represents pending pods.\n",
      "\t* Dark blue area represents running pods.\n",
      "4. Containers restarted (by Pod):\n",
      "\t* Bumps in the metric indicate container restarts, which is a problem for Haskell apps.\n",
      "5. Process monitor:\n",
      "\t* CloudWatch, Load Balancers Dashboard, and RDS Performance Insights are linked.\n",
      "\t* Significant spikes in Sessions are investigated using Zoom-in functionality.\n",
      "6. MySQL performance issues:\n",
      "\t* Spikes above Max vCPU cause contention.\n",
      "\t* Wait types indicate what MySQL threads were doing (mostly).\n",
      "\t* Slice by SQL is used to identify time-consuming queries.\n",
      "\n",
      "The report also includes a list of participants who have gone through the drill and those who are missing.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Firefighting Resources\n",
      "\n",
      "Big list of alert types and response playbooks.\n",
      "\n",
      "Slack:\n",
      "\n",
      "eng-ops-changes has information on manually performed operations, which may have caused an alert\n",
      "\n",
      "#ask-team-foxen - the slack channel for the infrastructure and tooling team.  Shout loudly here if there’s a concern with any infrastructure (cluster, db, networking) owned by NoRedInk.\n",
      "\n",
      "#nri-doit - our collab channel with DoiT International with whom we’ve partnered to provide us with debugging and consulting.  If you leave a message here you’ll probably be instructed to open a ticket.  Median ticket response time is ~30 minutes.\n",
      "\n",
      "Content Creation Service is not documented below, as it’s not on any user-facing request paths.\n",
      "\n",
      "GitHub admin rights to NoRedInk\n",
      "\n",
      "Only \n",
      "Only Computer Helpy Club has admin rights to our main NoRedInk repo. If you need admin rights as part a firefighting response, you may login in GitHub as **NoRedInkFireFighter**. Find the credentials in 1password.\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "Frequent fire-fighting measures\n",
      "\n",
      "Production env & basic info\n",
      "\n",
      "Demo env info\n",
      "\n",
      "Investigating servers and databases\n",
      "\n",
      "Investigating application behavior\n",
      "\n",
      "Deploying & fixing\n",
      "\n",
      "Frequent fire-fighting measures\n",
      "\n",
      "Debugging database performance issues in the Monolith\n",
      "\n",
      "How to tell?\n",
      "If Summary in NewRelic shows MySQL is taking an unusual slice of our transaction time, it’s very likely it’s a DB performance issue\n",
      "What to do\n",
      "\n",
      "Databases tab in NewRelic can help identify sources of slowness and trace them back to Transactions\n",
      "\n",
      "AWS Console → RDS → Performance Insights shows active queries and query state with up to 2s precision 😻\n",
      "\n",
      "show processlist or show full processlist in Sequel Pro\n",
      "Can help spot stuck queries (running for too long)\n",
      "You can kill them with [CALL mysql.rds_kill(ID)](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.MySQL.CommonDBATasks.html#Appendix.MySQL.CommonDBATasks.Kill)\n",
      "\n",
      "If the database is at 100% CPU\n",
      "You can try slowing down the quiz engine as it’s usually the biggest source of DB time consumption\n",
      "You can try spinning down a few Monolith servers to cause request queuing and lower throughput to the database\n",
      "\n",
      "If not, and request queueing is already very high, you can try spinning up more Monolith servers to absorb request queueing\n",
      "\n",
      "Haskell Quiz Engine Problems?\n",
      "\n",
      "How to tell?\n",
      "\n",
      "web external is super high\n",
      "\n",
      "“External Services” tab shows that HQE has the “slowest average response time” (it usually is the most time consuming because of volume of traffic).\n",
      "\n",
      "What to do?\n",
      "\n",
      "disable all HQE feature flags (off is safer)\n",
      "\n",
      "check in on HQE firefighting notes\n",
      "\n",
      "Fighting a DDoS attack\n",
      "\n",
      "How to tell?\n",
      "\n",
      "An unusual bump in traffic (see the Throughput  chart in the Summary page in NewRelic)\n",
      "\n",
      "They’re usually simplistic and hit one or very few endpoints (see the Transactions in NewRelic and open a few of them. Zooming in around the traffic bump and sorting transactions by Throughput also helps spot them)\n",
      "\n",
      "What to do\n",
      "\n",
      "[ ] Log into Cloudflare (creds in 1pw) and select our website (noredink.com)\n",
      "- Is the website going down?\n",
      "    - Yes\n",
      "        [ ] Click Under Attack Mode in the Quick Actions pane on the right\n",
      "            - ⚠️ This will cause all users to be challenged to prove they’re human when trying to access our website, including logged-in users, and might break our front-end.\n",
      "                - Users will get a 429 response code with HTML for the challenge page. This might break AJAX requests for users who were already logged in and in the middle of a flow that does AJAX requests. We did work to handle 429 responses, but it’s unclear how much of our site is or still is covered.\n",
      "                [ ] Let support know what to expect\n",
      "        [ ] Wait 30min / 1h and try turning it off (watch the Block  count in Firewall Events to see whether the attack is still ongoing)\n",
      "    - No, just slow enough to frustrate users\n",
      "        [ ] Try to identify which routes are being hit using NewRelic’s Transactions tab\n",
      "        [ ] Add a rate limiting rule to one or more of the routes, judging by which would be the least disruptive to users\n",
      "            - Advice: We had to fight 300k RPM DDoS attacks with as low as 10 requests per 1 minute limits, as some attacks use a very high number of bots making sparse requests\n",
      "            - ⚠️ This can still disrupt schools, as most schools provide internet access through a single or very few IP addresses, and a single class with 10-40 students all starting class can easily hit the rate limit\n",
      "            [ ] Let support know what to expect\n",
      "    [ ] No, just high throughput\n",
      "        - Watch it closely and wait it out, DDoS measures disrupt user experience and they’re not worth it in this case.\n",
      "\n",
      "Production & basic info\n",
      "\n",
      "Key activities that cause significant user pain if broken on prod i.e. What does this service do? Consider a 🔥 if … is broken on prod and causing widespread user pain Architecture overview Get help Monolith - Teacher: Assign work and view data - Student: Answer quiz engine questions and go through writing assignments - Both: Sign up and log in - Teacher: Assign work and view data - Student: Answer quiz engine questions and go through writing assignments - Both: Sign up and log in - Link - Deploy process overview - Environment-specific quirks - +Curriculum Actions That Will Break Things Reports - /admin/schools/ route becomes unavailable [Zamboni is planning to address as part of this story ] - Non-cached sections of premium reports that grab data from the service may not be available - 🔥 If Account Executives are unable to prepare for daily Sales calls because free usage reports are broken - 🔥 if reports-service-db-production-db is inaccessible - Not a fire if question_usages is inaccessible Link Slack: #ask-team-zen CleverSync - Biggest pain sync failure when user is initially added (these users have just activated clever or logged in and want content) - Out of date courses, not present or missing students - 🔥 Clever classes and rosters are not syncing for at least an hour Link Slack: #ask-team-zen Tutorials - Students won’t see any tutorials if the tutorial service is down. But they shouldn’t be blocked (tutorials will be skipped). n/a: students will skip tuts if service is down TBD Slack: #team- foxen Drafts - Students will be blocked from working on Guided Drafts or Self Reviews - Students will be blocked from seeing previous results on Guided Drafts or Self Reviews - Teachers will be blocked from grading and viewing results of Guided Drafts or Self Reviews - Students are unable to save writing - Teachers are unable to load writing - being unable to load titles on a class results page is fine if teachers can load the rest of the page. +ℹ️ All about the Drafts Service More firefighting notes: +Drafts Service Firefighting Notes Slack: #team- r aven-roost Rostering - Teachers will not be able to refer NoRedInk to others. - Teachers will not be able to browse content by standards or tests  at /curriculum/standards - (Coming soon) Teachers will not be able to browse /curriculum/planning-diagnostic premades It is not critical that teacher cannot add a referral, though it should be escalated to Kraken. It is also not critical that teachers be able to browse content by standards & tests or be able to access planning diagnostic premades. Escalate to Kraken. +ℹ️ Rostering Service +Standards V2 Documentation (Coming soon) Planning Diagnostic Premades Documentation +Haskell Service Playbook Slack: #team-kraken Slack: #team-puffin QuizEngine HTTP - Students will not be able to do quizzes. - Students are not able to do quizzes. - Quiz results pages are not loading. README.md +Curriculum Actions That Will Break Things Monitoring Resources Slack: #team-pufferfish\n",
      "\n",
      "Demo info\n",
      "\n",
      "See +Demo Script for QA for how the demo site is used by Partnerships.\n",
      "\n",
      "Consider a 🔥 if … is broken on demo How it’s set up on Demo Monolith tbd Dedicated service Reports If sections in the mock school or district premium reports are not displaying data or are otherwise not viewable Mocked out in the monolith CleverSync No, unless a district is using it for their BTS prep - Is a district using demo and CleverSync for BTS prep: :no: If the above is :yes: , the following needs to be working: - [To be filled out / updated when a district starts using demo for BTS prep] Dedicated service Tutorials tbd Points at production service Drafts If loading a student’s full essay view is not working. Dedicated service Rostering tbd Feature is disabled QuizEngine If the quiz engine views are not loading. Dedicated service\n",
      "\n",
      "Investigating servers and databases\n",
      "\n",
      "See the current state of specific infrastructure pieces Check connectivity to database etc Check database availability and monitoring Monolith CloudWatch - Covers pretty much everything New Relic Plugins - Load balancer, database, Redis, SendGrid - Easier to correlate with APM than CloudWatch Datadog infrastructure list - EC2 instances and load balancer Healthcheck URL - checks: web app, database AWS console for prod Datadog dash for prod AWS console for demo Datadog dash for demo Reports CloudWatch Datadog infrastructure list - EC2 instances, DBs and load balancer Healthcheck URL - checks: webapp CleverSync CloudWatch Healthcheck URL - checks: webapp Content-Creation Healthcheck URL checks: auth, bugsnag, monolith, mysql, newrelic, postgres - Production - Staging Tutorials - CloudWatch - Datadog: Haskell Services in Kubernetes - Look under “Saved views” - Kubernetes Nodes Overview - Kubernetes Pods Overview Healthcheck URL - checks: webapp, database, monolith auth api, rollbar - Production - Backyard Drafts - CloudWatch - Datadog: Haskell Services in Kubernetes - Look under “Saved views” - Kubernetes Nodes Overview - Kubernetes Pods Overview Healthcheck URL - checks: webapp, database - Production Database in AWS - Staging Database in AWS Rostering CloudWatch Healthcheck URL - checks: auth, mysql, postgres - Production - Staging QuizEngine - CloudWatch - Datadog: Haskell Services in Kubernetes - Look under “Saved views” - Kubernetes Nodes Overview - Kubernetes Pods Overview Healthcheck URL - checks: mysql, redis - Datadog Redis Cluster - Uses the same MySQL database as the monolith.\n",
      "\n",
      "Investigating application behavior\n",
      "\n",
      "Drill down into response time and performance bottlenecks See the details of the errors happening See the application logs SSH into app servers Monolith New Relic APM - Rollbar web - Slack: #eng-rollbar - New Relic APM error analytics (may have errors from Resque tasks not captured by Rollbar) ssh and look inside /opt/noredink/shared/log You should have been granted access as part of onboarding . Use script/servers.rb to find out the IP address . Reports New Relic APM - Rollbar web - Slack: #eng-rollbar-reports ssh and view /var/log/syslog . grep for [reports_service](https://github.com/NoRedInk/reports/blob/master/iac/reports_service.service#L17) tunnel.sh Content-Creation - New Relic APM - Datadog dashboard - Bugsnag web CloudWatch Logs Instructions CleverSync - New Relic APM - Datadog dashboard - Rollbar web - Slack: #eng-rollbar -clever ssh and view /var/log/syslog . grep for [clever_sync](https://github.com/NoRedInk/CleverSync/blob/master/iac/clever_sync.service#L17) More Info tunnel.sh Tutorials - New Relic APM - Datadog dashboard - Bugsnag web - Slack: #eng-rollbar-tutorials Datadog logs +Debugging live on Kubernetes Drafts - New Relic APM - Datadog dashboard - Datadog: Haskell Services in Kubernetes - Look under “Saved views” - Drafts Bugsnag - Monolith Bugsnag search for drafts items (may not be comprehensive) Datadog logs: - Production - Staging +Debugging live on Kubernetes Rostering - +Canvas and Schoology Tech Documentation: 🔥-Firefighting-🔥 - New Relic APM - Datadog dashboard - Bugsnag web - Monolith Rollbar items (may not be comprehensive) CloudWatch Logs Instructions QuizEngine - New Relic APM - Datadog dashboard - Bugsnag web +Debugging live on Kubernetes: Logs +Debugging live on Kubernetes\n",
      "\n",
      "Deploying & fixing\n",
      "\n",
      "[ ] Currently deployed revision When was a PR deployed? Turn off the service Change configuration / environment variable Deploy a hotfix Safely reboot an instance (without causing user pain / data loss / etc) Monolith Quick: Tip of the [production](https://github.com/NoRedInk/NoRedInk/commits/production) branch Most accurate: /opt/noredink/current/REVISION of any app server Search for the PR number or branch name in #eng-notify-info For demo, search in #demo-status - maintenance mode - throttle requests to the quiz engine - flipper has various feature flags named *killswitch* that turns off a particular feature Follow the wiki page for adding an env var. In a pinch, update the SSM param with awscli and propagate the change following the subsequent steps. Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance Reports edeliver or ssh to completely stop the service Follow this doc Deploy steps Stop instructions (stop / start / restart) or SSH Instructions /home/web/reports_service/bin/reports_service ping should return “pong” if the instance is up. Navigate to https://www.noredink.com/admin/schools/136615/report and verify the service is returning data Content-Creation Quick: Tip of deployed branch Most accurate: /home/web/revision of any app server flip [content_creation_killswitch](https://staging.noredink.com/admin/flipper/features/content_creation_killswitch) Follow the how-to doc (CodeDeploy-based project) Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance CleverSync edeliver or ssh to completely stop the service. Follow the how-to doc Deploy steps SSH Instructions /home/web/clever_sync/bin/clever_sync restart /home/web/clever_sync/bin/clever_sync ping should return “pong” if the instance is up. Tutorials Quick: Tip of the [deployed/tutorials/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/tutorials/production) branch Most accurate: +Debugging live on Kubernetes: Get-deployment’s-YAML and grep for “image”. The image tag is suffixed by the git hash. Flip :tutorials_service_killswitch killswitch Follow the how-to doc (Kubernetes-based project) Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance Drafts Quick: Tip of the [deployed/drafts/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/drafts/production) branch Most accurate: +Debugging live on Kubernetes: Get-deployment’s-YAML and grep for “image”. The image tag is suffixed by the git hash. Kill switch: drafts_service_killswitch . Use in any firefighting scenario where traffic must be cut off from the drafts service. The monolith handles this kill switch gracefully, and will show a nice error message to the user. Follow the how-to doc (CodeDeploy-based project) Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance Rostering Quick: Tip of the [deployed/rostering/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/rostering/production) branch Most accurate: /home/web/revision of any app server - Rostering service killswitch: r``eferrals``_service_killswitch - Customer.io requests from the rostering service: r``eferrals``_service_customerio_sleepswitch - /curriculum/standards killswitch: standards_service_killswitch - /curriculum/planning-diagnostic premades killswitch: quiz_engine_premades_service_killswitch Follow the how-to doc (CodeDeploy-based project) Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance QuizEngine Quick: Tip of the [deployed/](https://github.com/NoRedInk/NoRedInk/commits/deployed/quiz-engine-http/production)``[quiz-engine-http](https://github.com/NoRedInk/NoRedInk/commits/deployed/quiz-engine-http/production)``[/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/quiz-engine-http/production) branch Most accurate: +Debugging live on Kubernetes: Get-deployment’s-YAML and grep for “image”. The image tag is suffixed by the git hash. - Check out firefighting header in the readme - Follow the how-to doc (Kubernetes-based project) - Check out firefighting header in the readme Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance\n",
      "\n",
      "List of services for copy&pasting\n",
      "\n",
      "Monolith Reports Content-Creation CleverSync Tutorials Drafts Rostering QuizEngine\n",
      "\n",
      "This table is tentatively retired due to the suspicion that it’s become too big to be useful\n",
      "\n",
      "Monolith Reports CleverSync Tutorials Drafts Rostering Key activities that cause significant user pain if broken on prod - Teacher: Assign work and view data - Student: Answer quiz engine questions and go through writing assignments - Both: Sign up and log in - /admin/schools/ route becomes unavailable [Zamboni is planning to address as part of this story ] - Non-cached sections of premium reports that grab data from the service may not be available - Biggest pain sync failure when user is initially added (these users have just activated clever or logged in and want content) - Out of date courses, not present or missing students - Students won’t see any tutorials if the tutorial service is down. But they shouldn’t be blocked (tutorials will be skipped). - Students will be blocked from working on Guided Drafts or Self Reviews - Students will be blocked from seeing previous results on Guided Drafts or Self Reviews - Teachers will be blocked from grading and viewing results of Guided Drafts or Self Reviews - Teachers will not be able to refer NoRedInk to others. Consider a 🔥 if … is broken on prod - Teacher: Assign work and view data - Student: Answer quiz engine questions and go through writing assignments - Both: Sign up and log in Yes Yes n/a: students will skip tuts if service is down tbd tbd Consider a 🔥 if … is broken on demo tbd N/A No, unless a district is using it for their BTS prep tbd tbd n/a feature is disabled How it’s set up on Demo Dedicated service Mocked out Dedicated service No separate service Dedicated service Feature is disabled Drill down into response time and performance bottlenecks New Relic APM New Relic APM - New Relic APM - Datadog dashboard - New Relic APM - Datadog dashboard - New Relic APM - Datadog dashboard - New Relic APM - Datadog dashboard See the current state of specific infrastructure pieces CloudWatch - Covers pretty much everything New Relic Plugins - Load balancer, database, Redis, SendGrid - Easier to correlate with APM than CloudWatch Datadog infrastructure list - EC2 instances and load balancer CloudWatch Datadog infrastructure list - EC2 instances, DBs and load balancer CloudWatch CloudWatch CloudWatch CloudWatch Check database availability and monitoring AWS console for prod Datadog dash for prod AWS console for demo Datadog dash for demo - Production Database in AWS - Staging Database in AWS - Production - Staging See the details of the errors happening - Rollbar web - Slack: #eng-rollbar - New Relic APM error analytics (may have errors from Resque tasks not captured by Rollbar) - Rollbar web - Slack: #eng-rollbar-reports - Rollbar web - Slack: #eng-rollbar -clever - Bugsnag web - Slack: #eng-rollbar-tutorials - Drafts Bugsnag - Drafts Rollbar (same info as Bugsnag, will be shut down at some point in the future in favor of Bugsnag) - Monolith Rollbar search for drafts items (may not be comprehensive) - Bugsnag web - Monolith Rollbar items (may not be comprehensive) See the application logs ssh and look inside /opt/noredink/shared/log ssh and view /var/log/syslog . grep for [reports_service](https://github.com/NoRedInk/reports/blob/master/iac/reports_service.service#L17) ssh and view /var/log/syslog . grep for [clever_sync](https://github.com/NoRedInk/CleverSync/blob/master/iac/clever_sync.service#L17) More Info Cloudwatch logs Logs are written to CloudWatch. - Application Logs - Access Logs CloudWatch Logs SSH into app servers You should have been granted access as part of onboarding . Use script/servers.rb to find out the IP address . tunnel.sh tunnel.sh You can ssh in using the root ssh key found in 1Password. Detailed instructions here. You can ssh in using the root ssh key found in 1Password. Use the AWS UI to find out IP addresses. Detailed instructions here. Instructions Turn off the service - maintenance mode - throttle requests to the quiz engine - flipper has various feature flags named *killswitch* that turns off a particular feature edeliver or ssh to completely stop the service edeliver or ssh to completely stop the service. Flip :tutorials_service_killswitch killswitch Kill switch: drafts_service_killswitch . Use in any firefighting scenario where traffic must be cut off from the drafts service. The monolith handles this kill switch gracefully, and will show a nice error message to the user. - Rostering service killswitch: :rostering_service_killswitch - Customer.io requests from the rostering service: :rostering_service_customerio_sleepswitch Currently deployed revision Quick: Tip of the [production](https://github.com/NoRedInk/NoRedInk/commits/production) branch Most accurate: /opt/noredink/current/REVISION of any app server Quick: Tip of the [deployed/tutorials/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/tutorials/production) branch Most accurate: /home/web/revision of any app server Quick: Tip of the [deployed/drafts/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/drafts/production) branch Most accurate: /home/web/revision of any app server Quick: Tip of the [deployed/rostering/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/rostering/production) branch Most accurate: /home/web/revision of any app server When was a PR deployed? Search for the PR number or branch name in #eng-notify-info For demo, search in #demo-status Deploy a hotfix Real emergency: upload directly . Otherwise, follow the regular hotfix process. Deploy steps Deploy steps Follow the regular Haskell Monorepo deploy process Follow the regular Haskell Monorepo deploy process Follow the regular Haskell Monorepo deploy process Check connectivity to database etc Healthcheck URL - checks: webapp, database Healthcheck URL - checks: webapp Healthcheck URL - checks: webapp Healthcheck URL - checks: webapp, database, monolith auth api, rollbar Healthcheck URL - checks: webapp, database Healthcheck URL - checks: auth, mysql, postgres Architecture overview - Link - Deploy process overview - Environment-specific quirks Link Link TBD +ℹ️ All about the Drafts Service +ℹ️ Rostering Service Get help Slack: #ask-team-zen Slack: #ask-team-zen Slack: #team-puffin More firefighting notes: +Drafts Service Firefighting Notes Slack: #team-labradoodle +Haskell Service Playbook Slack: #team-ink Slack: #team-puffin\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='🔥 Fire triage drill\\n\\nNote: This document is not intended to be consumed by itself. I’m personally introducing fire fighters to this drill at the start of their on-call cycle, and the document is here for a) reference for me b) reference for fire fighters after our meeting.\\n\\nThe fire drill starts at the NewRelic APM main screen for the Monolith. Go through the numbers on the image, reading their description below, and follow the arrows ➡️ .\\n\\nNewRelic\\n\\nMonolith NewRelic main screen\\n\\n🔗 Link\\n\\nRequest breakdown\\nDid something start taking up a larger share of request time?\\nExternal services\\n➡️ Go to the External Services tab in the right and figure out which service\\n\\n\\nDB\\n➡️ Go to the Databases tab and see whether some transactions started spiking\\n➡️ Open RDS Performance Insights for higher resolution data\\n\\n\\nQueueing or Ruby Slowness\\n➡️ Open Load Balancers Dashboard\\n➡️ Opsworks time-based instances and load-based instances\\nDo we have instances booting up?\\n\\nThroughput\\nDo we have a huge spike in throughput? 200k RPM and above might mean we’re under a DDoS attack\\n➡️ Check out what to do here: +Firefighting Resources: Fighting-a-DDoS-attack\\n\\nError rate\\nAre error spiking? Like 1% or more\\n➡️ Go to Errors tab\\n➡️ Check out Bugsnag (finer grained timeline)\\n\\nExternal Services\\n\\nServices by total response time\\nAny service started taking a longer time than usual?\\nA Haskell service?\\n➡️ Go to the specific service’s dashboard in NewRelic and do a similar analysis there (what made it slow? etc)\\n➡️ Also, open the Haskell Services in Kubernete dashboard in Datadog, because Kubernetes might be at fault\\nWhat services are in Kubernetes?\\nDrafts\\nQuiz Engine\\nTutorials\\n\\n\\n\\n\\n\\n\\nAn Elixir service?\\n➡️ Go to the specific service’s dashboard in NewRelic and do a similar analysis there (what made it slow? etc)\\n🗒️ This never happened. Elixir reacts well to increased load. No Elixir services are set up for horizontal scalability tho, so the only alternative if this happens is:\\n➡️ Increase the instance size (start by looking at the service’s repo, they all have an iac directory with terraform stuff)\\n\\n\\n\\n\\nThird-party service?\\nIs it bringing the site down?\\n➡️ Check if there’s a killswitch for functionality that talks to this service\\n\\nClick the service to get throughput and response time. If it’s our service, the service’s own NewRelic dashboard will show more details tho.\\n\\nDatabases\\n\\nCheck if any DB operations are spiking\\nYou can click ActiveRecord or MySQL on the top left to see more activerecord/mysql queries in the graph, if nothing is spiking\\nSometimes everything is spiking, or lots of things are, and in these cases it’s more likely a general MySQL problem\\n➡️ Diagnose further on RDS Performance Insights\\n\\nClick on the spiky operation\\n\\nDatadog\\n\\nDatadog\\n\\nTwo main things here:\\n\\nHaskell in Kubernetes Dashboard\\nA dashboard with 90% of what you need to triage fires in Haskell services deployed to Kubernetes\\n\\nProcess Monitor\\nLike htop, but in Datadog. Useful for seeing Threads per process and what % a process is taking over the entire machine.\\n\\nHaskell in Kubernetes Dashboard\\n\\n🔗 Link\\n\\nIs CPU usage in the monolith too high? Above 48% is too high.\\n\\nIs load average for Kubernetes too high?\\nℹ️ It might indicate contention in one or more services\\nℹ️ If it correlates with IOWait spikes, it might indicate network/disk contention\\n\\nIs memory usage too high? Around 80~90% is too high\\n➡️ Scroll down to Memory usage by container to quickly check if it’s the application you’re browsing\\n➡️ A more in-depth investigation can be done in the Process Monitor\\n\\nAre nodes scaling up?\\n\\nThe dotted lines show last week, for comparison.\\nKubernetes doesn’t scale up on a schedule, rather on-demand, so solid and dotted lines matching is not strictly required.\\n\\nMemory Usage by Container\\n\\nLight orange line: limits.memory in Kubernetes. Once reached, the container gets killed. Kube will re-start the container, but meanwhile, all requests to it will bounce as 5xx.\\nDark orange line: Haskell RTS Heap limit (-M). Once reached the RTS should self-destruct. Kube will notice and re-start the container, but meanwhile all requests to it will bounce as 5xx.\\nDark red line: Garbage collector “compaction” threshold. After this threshold the GC will start using compaction and we should observe increased CPU usage and/or increased response time.\\n\\nCPU Usage by Container\\nℹ️ This chart is passed over a smoothing function to make patterns easier to spot. Values don’t reflect reality, only trends.\\n:tip: This chart makes it easy to spot Pods coming up and going down bc of auto-scaling.\\nYellow line: requests.cpu in Kubernetes. How much we expect this Pod to use at most.\\n\\nPod count (desired and actual)\\nDotted red line: Desired replicas. How many Pods the HorizontalPodAutoscaler thinks we should have based on CPU usage.\\nSolid orange line: Actual replicas. How many Pods the HorizontalPodAutoscaler sees.\\nLight blue area: Pending Pods. How many Pods are scheduled to run in an available node, or a node that’s booting up, but are not yet running.\\nDark blue area: Running pods. How many Pods are actually running.\\nℹ️ Pods pending for too long is a problem. They shouldn’t remain in Pending for longer than 3 minutes.\\nℹ️ Aside from auto-scaling, this changes during blue-green deploys, where we double our fleet.\\n\\nContainers restarted (by Pod)\\nBumps in this metric represent times a container has restarted inside a Pod.\\nℹ️ We have an on-going container restart problem in Haskell apps.\\n\\nProcess monitor\\n\\n🔗 Link\\n\\nCloudWatch\\n\\nLoad Balancers Dashboard\\n\\n🔗 Link\\n\\nRDS Performance Insights\\n\\n🔗 Link\\n\\nAre there any significant spikes in Sessions?\\n➡️ Zoom into the spikes. Performance Insights has per-second resolution, so you’ll see more interesting patterns by zooming in.\\nℹ️ Spikes above Max vCPU tend to cause contention\\n🗒️ The wait types are related to MySQL Thread State and indicate what were MySQL threads doing, mostly, on average\\n\\nSwitch from Slice by wait to Slice by SQL to get a sense of what queries were responsible for congestion\\n\\nBy clicking the + sign in the table below you will find samples of the most time-consuming queries with their actual params (truncated, unfortunately).\\n\\nℹ️ MySQL has been having hiccups on writes, and they manifest like this:\\n\\nThey usually last a few seconds and go away. We don’t have a solution nor understand root cause yet.\\n\\nBugsnag\\n\\n🔗 Link\\n\\nAppendix\\n\\nWho’s gone through the drill?\\n\\nJuan\\n\\nStöffel\\n\\nBlake\\n\\nJasper\\n\\nAlly\\n\\nIan\\n\\nAlex Perkins\\n\\nRichard\\n\\nTessa\\n\\nJu\\n\\nCharlie\\n\\nNuno\\n\\nJuan Wajnerman\\n\\nWho’s missing?\\n\\nAry\\n\\nBrian C\\n\\nBrian H\\n\\nGlass\\n\\nMike Steder', metadata={'source': '.content/Engineering/Fires/Fire_triage_drill.md'}),\n",
       "  Document(page_content='Firefighting Resources\\n\\nBig list of alert types and response playbooks.\\n\\nSlack:\\n\\neng-ops-changes has information on manually performed operations, which may have caused an alert\\n\\n#ask-team-foxen - the slack channel for the infrastructure and tooling team.  Shout loudly here if there’s a concern with any infrastructure (cluster, db, networking) owned by NoRedInk.\\n\\n#nri-doit - our collab channel with DoiT International with whom we’ve partnered to provide us with debugging and consulting.  If you leave a message here you’ll probably be instructed to open a ticket.  Median ticket response time is ~30 minutes.\\n\\nContent Creation Service is not documented below, as it’s not on any user-facing request paths.\\n\\nGitHub admin rights to NoRedInk\\n\\nOnly \\nOnly Computer Helpy Club has admin rights to our main NoRedInk repo. If you need admin rights as part a firefighting response, you may login in GitHub as **NoRedInkFireFighter**. Find the credentials in 1password.\\n\\nTable of Contents\\n\\nFrequent fire-fighting measures\\n\\nProduction env & basic info\\n\\nDemo env info\\n\\nInvestigating servers and databases\\n\\nInvestigating application behavior\\n\\nDeploying & fixing\\n\\nFrequent fire-fighting measures\\n\\nDebugging database performance issues in the Monolith\\n\\nHow to tell?\\nIf Summary in NewRelic shows MySQL is taking an unusual slice of our transaction time, it’s very likely it’s a DB performance issue\\nWhat to do\\n\\nDatabases tab in NewRelic can help identify sources of slowness and trace them back to Transactions\\n\\nAWS Console → RDS → Performance Insights shows active queries and query state with up to 2s precision 😻\\n\\nshow processlist or show full processlist in Sequel Pro\\nCan help spot stuck queries (running for too long)\\nYou can kill them with [CALL mysql.rds_kill(ID)](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.MySQL.CommonDBATasks.html#Appendix.MySQL.CommonDBATasks.Kill)\\n\\nIf the database is at 100% CPU\\nYou can try slowing down the quiz engine as it’s usually the biggest source of DB time consumption\\nYou can try spinning down a few Monolith servers to cause request queuing and lower throughput to the database\\n\\nIf not, and request queueing is already very high, you can try spinning up more Monolith servers to absorb request queueing\\n\\nHaskell Quiz Engine Problems?\\n\\nHow to tell?\\n\\nweb external is super high\\n\\n“External Services” tab shows that HQE has the “slowest average response time” (it usually is the most time consuming because of volume of traffic).\\n\\nWhat to do?\\n\\ndisable all HQE feature flags (off is safer)\\n\\ncheck in on HQE firefighting notes\\n\\nFighting a DDoS attack\\n\\nHow to tell?\\n\\nAn unusual bump in traffic (see the Throughput  chart in the Summary page in NewRelic)\\n\\nThey’re usually simplistic and hit one or very few endpoints (see the Transactions in NewRelic and open a few of them. Zooming in around the traffic bump and sorting transactions by Throughput also helps spot them)\\n\\nWhat to do\\n\\n[ ] Log into Cloudflare (creds in 1pw) and select our website (noredink.com)\\n- Is the website going down?\\n    - Yes\\n        [ ] Click Under Attack Mode in the Quick Actions pane on the right\\n            - ⚠️ This will cause all users to be challenged to prove they’re human when trying to access our website, including logged-in users, and might break our front-end.\\n                - Users will get a 429 response code with HTML for the challenge page. This might break AJAX requests for users who were already logged in and in the middle of a flow that does AJAX requests. We did work to handle 429 responses, but it’s unclear how much of our site is or still is covered.\\n                [ ] Let support know what to expect\\n        [ ] Wait 30min / 1h and try turning it off (watch the Block  count in Firewall Events to see whether the attack is still ongoing)\\n    - No, just slow enough to frustrate users\\n        [ ] Try to identify which routes are being hit using NewRelic’s Transactions tab\\n        [ ] Add a rate limiting rule to one or more of the routes, judging by which would be the least disruptive to users\\n            - Advice: We had to fight 300k RPM DDoS attacks with as low as 10 requests per 1 minute limits, as some attacks use a very high number of bots making sparse requests\\n            - ⚠️ This can still disrupt schools, as most schools provide internet access through a single or very few IP addresses, and a single class with 10-40 students all starting class can easily hit the rate limit\\n            [ ] Let support know what to expect\\n    [ ] No, just high throughput\\n        - Watch it closely and wait it out, DDoS measures disrupt user experience and they’re not worth it in this case.\\n\\nProduction & basic info\\n\\nKey activities that cause significant user pain if broken on prod i.e. What does this service do? Consider a 🔥 if … is broken on prod and causing widespread user pain Architecture overview Get help Monolith - Teacher: Assign work and view data - Student: Answer quiz engine questions and go through writing assignments - Both: Sign up and log in - Teacher: Assign work and view data - Student: Answer quiz engine questions and go through writing assignments - Both: Sign up and log in - Link - Deploy process overview - Environment-specific quirks - +Curriculum Actions That Will Break Things Reports - /admin/schools/ route becomes unavailable [Zamboni is planning to address as part of this story ] - Non-cached sections of premium reports that grab data from the service may not be available - 🔥 If Account Executives are unable to prepare for daily Sales calls because free usage reports are broken - 🔥 if reports-service-db-production-db is inaccessible - Not a fire if question_usages is inaccessible Link Slack: #ask-team-zen CleverSync - Biggest pain sync failure when user is initially added (these users have just activated clever or logged in and want content) - Out of date courses, not present or missing students - 🔥 Clever classes and rosters are not syncing for at least an hour Link Slack: #ask-team-zen Tutorials - Students won’t see any tutorials if the tutorial service is down. But they shouldn’t be blocked (tutorials will be skipped). n/a: students will skip tuts if service is down TBD Slack: #team- foxen Drafts - Students will be blocked from working on Guided Drafts or Self Reviews - Students will be blocked from seeing previous results on Guided Drafts or Self Reviews - Teachers will be blocked from grading and viewing results of Guided Drafts or Self Reviews - Students are unable to save writing - Teachers are unable to load writing - being unable to load titles on a class results page is fine if teachers can load the rest of the page. +ℹ️ All about the Drafts Service More firefighting notes: +Drafts Service Firefighting Notes Slack: #team- r aven-roost Rostering - Teachers will not be able to refer NoRedInk to others. - Teachers will not be able to browse content by standards or tests  at /curriculum/standards - (Coming soon) Teachers will not be able to browse /curriculum/planning-diagnostic premades It is not critical that teacher cannot add a referral, though it should be escalated to Kraken. It is also not critical that teachers be able to browse content by standards & tests or be able to access planning diagnostic premades. Escalate to Kraken. +ℹ️ Rostering Service +Standards V2 Documentation (Coming soon) Planning Diagnostic Premades Documentation +Haskell Service Playbook Slack: #team-kraken Slack: #team-puffin QuizEngine HTTP - Students will not be able to do quizzes. - Students are not able to do quizzes. - Quiz results pages are not loading. README.md +Curriculum Actions That Will Break Things Monitoring Resources Slack: #team-pufferfish\\n\\nDemo info\\n\\nSee +Demo Script for QA for how the demo site is used by Partnerships.\\n\\nConsider a 🔥 if … is broken on demo How it’s set up on Demo Monolith tbd Dedicated service Reports If sections in the mock school or district premium reports are not displaying data or are otherwise not viewable Mocked out in the monolith CleverSync No, unless a district is using it for their BTS prep - Is a district using demo and CleverSync for BTS prep: :no: If the above is :yes: , the following needs to be working: - [To be filled out / updated when a district starts using demo for BTS prep] Dedicated service Tutorials tbd Points at production service Drafts If loading a student’s full essay view is not working. Dedicated service Rostering tbd Feature is disabled QuizEngine If the quiz engine views are not loading. Dedicated service\\n\\nInvestigating servers and databases\\n\\nSee the current state of specific infrastructure pieces Check connectivity to database etc Check database availability and monitoring Monolith CloudWatch - Covers pretty much everything New Relic Plugins - Load balancer, database, Redis, SendGrid - Easier to correlate with APM than CloudWatch Datadog infrastructure list - EC2 instances and load balancer Healthcheck URL - checks: web app, database AWS console for prod Datadog dash for prod AWS console for demo Datadog dash for demo Reports CloudWatch Datadog infrastructure list - EC2 instances, DBs and load balancer Healthcheck URL - checks: webapp CleverSync CloudWatch Healthcheck URL - checks: webapp Content-Creation Healthcheck URL checks: auth, bugsnag, monolith, mysql, newrelic, postgres - Production - Staging Tutorials - CloudWatch - Datadog: Haskell Services in Kubernetes - Look under “Saved views” - Kubernetes Nodes Overview - Kubernetes Pods Overview Healthcheck URL - checks: webapp, database, monolith auth api, rollbar - Production - Backyard Drafts - CloudWatch - Datadog: Haskell Services in Kubernetes - Look under “Saved views” - Kubernetes Nodes Overview - Kubernetes Pods Overview Healthcheck URL - checks: webapp, database - Production Database in AWS - Staging Database in AWS Rostering CloudWatch Healthcheck URL - checks: auth, mysql, postgres - Production - Staging QuizEngine - CloudWatch - Datadog: Haskell Services in Kubernetes - Look under “Saved views” - Kubernetes Nodes Overview - Kubernetes Pods Overview Healthcheck URL - checks: mysql, redis - Datadog Redis Cluster - Uses the same MySQL database as the monolith.\\n\\nInvestigating application behavior\\n\\nDrill down into response time and performance bottlenecks See the details of the errors happening See the application logs SSH into app servers Monolith New Relic APM - Rollbar web - Slack: #eng-rollbar - New Relic APM error analytics (may have errors from Resque tasks not captured by Rollbar) ssh and look inside /opt/noredink/shared/log You should have been granted access as part of onboarding . Use script/servers.rb to find out the IP address . Reports New Relic APM - Rollbar web - Slack: #eng-rollbar-reports ssh and view /var/log/syslog . grep for [reports_service](https://github.com/NoRedInk/reports/blob/master/iac/reports_service.service#L17) tunnel.sh Content-Creation - New Relic APM - Datadog dashboard - Bugsnag web CloudWatch Logs Instructions CleverSync - New Relic APM - Datadog dashboard - Rollbar web - Slack: #eng-rollbar -clever ssh and view /var/log/syslog . grep for [clever_sync](https://github.com/NoRedInk/CleverSync/blob/master/iac/clever_sync.service#L17) More Info tunnel.sh Tutorials - New Relic APM - Datadog dashboard - Bugsnag web - Slack: #eng-rollbar-tutorials Datadog logs +Debugging live on Kubernetes Drafts - New Relic APM - Datadog dashboard - Datadog: Haskell Services in Kubernetes - Look under “Saved views” - Drafts Bugsnag - Monolith Bugsnag search for drafts items (may not be comprehensive) Datadog logs: - Production - Staging +Debugging live on Kubernetes Rostering - +Canvas and Schoology Tech Documentation: 🔥-Firefighting-🔥 - New Relic APM - Datadog dashboard - Bugsnag web - Monolith Rollbar items (may not be comprehensive) CloudWatch Logs Instructions QuizEngine - New Relic APM - Datadog dashboard - Bugsnag web +Debugging live on Kubernetes: Logs +Debugging live on Kubernetes\\n\\nDeploying & fixing\\n\\n[ ] Currently deployed revision When was a PR deployed? Turn off the service Change configuration / environment variable Deploy a hotfix Safely reboot an instance (without causing user pain / data loss / etc) Monolith Quick: Tip of the [production](https://github.com/NoRedInk/NoRedInk/commits/production) branch Most accurate: /opt/noredink/current/REVISION of any app server Search for the PR number or branch name in #eng-notify-info For demo, search in #demo-status - maintenance mode - throttle requests to the quiz engine - flipper has various feature flags named *killswitch* that turns off a particular feature Follow the wiki page for adding an env var. In a pinch, update the SSM param with awscli and propagate the change following the subsequent steps. Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance Reports edeliver or ssh to completely stop the service Follow this doc Deploy steps Stop instructions (stop / start / restart) or SSH Instructions /home/web/reports_service/bin/reports_service ping should return “pong” if the instance is up. Navigate to https://www.noredink.com/admin/schools/136615/report and verify the service is returning data Content-Creation Quick: Tip of deployed branch Most accurate: /home/web/revision of any app server flip [content_creation_killswitch](https://staging.noredink.com/admin/flipper/features/content_creation_killswitch) Follow the how-to doc (CodeDeploy-based project) Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance CleverSync edeliver or ssh to completely stop the service. Follow the how-to doc Deploy steps SSH Instructions /home/web/clever_sync/bin/clever_sync restart /home/web/clever_sync/bin/clever_sync ping should return “pong” if the instance is up. Tutorials Quick: Tip of the [deployed/tutorials/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/tutorials/production) branch Most accurate: +Debugging live on Kubernetes: Get-deployment’s-YAML and grep for “image”. The image tag is suffixed by the git hash. Flip :tutorials_service_killswitch killswitch Follow the how-to doc (Kubernetes-based project) Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance Drafts Quick: Tip of the [deployed/drafts/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/drafts/production) branch Most accurate: +Debugging live on Kubernetes: Get-deployment’s-YAML and grep for “image”. The image tag is suffixed by the git hash. Kill switch: drafts_service_killswitch . Use in any firefighting scenario where traffic must be cut off from the drafts service. The monolith handles this kill switch gracefully, and will show a nice error message to the user. Follow the how-to doc (CodeDeploy-based project) Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance Rostering Quick: Tip of the [deployed/rostering/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/rostering/production) branch Most accurate: /home/web/revision of any app server - Rostering service killswitch: r``eferrals``_service_killswitch - Customer.io requests from the rostering service: r``eferrals``_service_customerio_sleepswitch - /curriculum/standards killswitch: standards_service_killswitch - /curriculum/planning-diagnostic premades killswitch: quiz_engine_premades_service_killswitch Follow the how-to doc (CodeDeploy-based project) Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance QuizEngine Quick: Tip of the [deployed/](https://github.com/NoRedInk/NoRedInk/commits/deployed/quiz-engine-http/production)``[quiz-engine-http](https://github.com/NoRedInk/NoRedInk/commits/deployed/quiz-engine-http/production)``[/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/quiz-engine-http/production) branch Most accurate: +Debugging live on Kubernetes: Get-deployment’s-YAML and grep for “image”. The image tag is suffixed by the git hash. - Check out firefighting header in the readme - Follow the how-to doc (Kubernetes-based project) - Check out firefighting header in the readme Follow the regular Haskell Monorepo deploy process +Debugging live on Kubernetes: Restarting-a-pod +Debugging live on Kubernetes: Safely-reboot-an-instance\\n\\nList of services for copy&pasting\\n\\nMonolith Reports Content-Creation CleverSync Tutorials Drafts Rostering QuizEngine\\n\\nThis table is tentatively retired due to the suspicion that it’s become too big to be useful\\n\\nMonolith Reports CleverSync Tutorials Drafts Rostering Key activities that cause significant user pain if broken on prod - Teacher: Assign work and view data - Student: Answer quiz engine questions and go through writing assignments - Both: Sign up and log in - /admin/schools/ route becomes unavailable [Zamboni is planning to address as part of this story ] - Non-cached sections of premium reports that grab data from the service may not be available - Biggest pain sync failure when user is initially added (these users have just activated clever or logged in and want content) - Out of date courses, not present or missing students - Students won’t see any tutorials if the tutorial service is down. But they shouldn’t be blocked (tutorials will be skipped). - Students will be blocked from working on Guided Drafts or Self Reviews - Students will be blocked from seeing previous results on Guided Drafts or Self Reviews - Teachers will be blocked from grading and viewing results of Guided Drafts or Self Reviews - Teachers will not be able to refer NoRedInk to others. Consider a 🔥 if … is broken on prod - Teacher: Assign work and view data - Student: Answer quiz engine questions and go through writing assignments - Both: Sign up and log in Yes Yes n/a: students will skip tuts if service is down tbd tbd Consider a 🔥 if … is broken on demo tbd N/A No, unless a district is using it for their BTS prep tbd tbd n/a feature is disabled How it’s set up on Demo Dedicated service Mocked out Dedicated service No separate service Dedicated service Feature is disabled Drill down into response time and performance bottlenecks New Relic APM New Relic APM - New Relic APM - Datadog dashboard - New Relic APM - Datadog dashboard - New Relic APM - Datadog dashboard - New Relic APM - Datadog dashboard See the current state of specific infrastructure pieces CloudWatch - Covers pretty much everything New Relic Plugins - Load balancer, database, Redis, SendGrid - Easier to correlate with APM than CloudWatch Datadog infrastructure list - EC2 instances and load balancer CloudWatch Datadog infrastructure list - EC2 instances, DBs and load balancer CloudWatch CloudWatch CloudWatch CloudWatch Check database availability and monitoring AWS console for prod Datadog dash for prod AWS console for demo Datadog dash for demo - Production Database in AWS - Staging Database in AWS - Production - Staging See the details of the errors happening - Rollbar web - Slack: #eng-rollbar - New Relic APM error analytics (may have errors from Resque tasks not captured by Rollbar) - Rollbar web - Slack: #eng-rollbar-reports - Rollbar web - Slack: #eng-rollbar -clever - Bugsnag web - Slack: #eng-rollbar-tutorials - Drafts Bugsnag - Drafts Rollbar (same info as Bugsnag, will be shut down at some point in the future in favor of Bugsnag) - Monolith Rollbar search for drafts items (may not be comprehensive) - Bugsnag web - Monolith Rollbar items (may not be comprehensive) See the application logs ssh and look inside /opt/noredink/shared/log ssh and view /var/log/syslog . grep for [reports_service](https://github.com/NoRedInk/reports/blob/master/iac/reports_service.service#L17) ssh and view /var/log/syslog . grep for [clever_sync](https://github.com/NoRedInk/CleverSync/blob/master/iac/clever_sync.service#L17) More Info Cloudwatch logs Logs are written to CloudWatch. - Application Logs - Access Logs CloudWatch Logs SSH into app servers You should have been granted access as part of onboarding . Use script/servers.rb to find out the IP address . tunnel.sh tunnel.sh You can ssh in using the root ssh key found in 1Password. Detailed instructions here. You can ssh in using the root ssh key found in 1Password. Use the AWS UI to find out IP addresses. Detailed instructions here. Instructions Turn off the service - maintenance mode - throttle requests to the quiz engine - flipper has various feature flags named *killswitch* that turns off a particular feature edeliver or ssh to completely stop the service edeliver or ssh to completely stop the service. Flip :tutorials_service_killswitch killswitch Kill switch: drafts_service_killswitch . Use in any firefighting scenario where traffic must be cut off from the drafts service. The monolith handles this kill switch gracefully, and will show a nice error message to the user. - Rostering service killswitch: :rostering_service_killswitch - Customer.io requests from the rostering service: :rostering_service_customerio_sleepswitch Currently deployed revision Quick: Tip of the [production](https://github.com/NoRedInk/NoRedInk/commits/production) branch Most accurate: /opt/noredink/current/REVISION of any app server Quick: Tip of the [deployed/tutorials/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/tutorials/production) branch Most accurate: /home/web/revision of any app server Quick: Tip of the [deployed/drafts/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/drafts/production) branch Most accurate: /home/web/revision of any app server Quick: Tip of the [deployed/rostering/production](https://github.com/NoRedInk/NoRedInk/commits/deployed/rostering/production) branch Most accurate: /home/web/revision of any app server When was a PR deployed? Search for the PR number or branch name in #eng-notify-info For demo, search in #demo-status Deploy a hotfix Real emergency: upload directly . Otherwise, follow the regular hotfix process. Deploy steps Deploy steps Follow the regular Haskell Monorepo deploy process Follow the regular Haskell Monorepo deploy process Follow the regular Haskell Monorepo deploy process Check connectivity to database etc Healthcheck URL - checks: webapp, database Healthcheck URL - checks: webapp Healthcheck URL - checks: webapp Healthcheck URL - checks: webapp, database, monolith auth api, rollbar Healthcheck URL - checks: webapp, database Healthcheck URL - checks: auth, mysql, postgres Architecture overview - Link - Deploy process overview - Environment-specific quirks Link Link TBD +ℹ️ All about the Drafts Service +ℹ️ Rostering Service Get help Slack: #ask-team-zen Slack: #ask-team-zen Slack: #team-puffin More firefighting notes: +Drafts Service Firefighting Notes Slack: #team-labradoodle +Haskell Service Playbook Slack: #team-ink Slack: #team-puffin', metadata={'source': '.content/Engineering/Fires/Firefighting_Resources.md'})],\n",
       " 'output_text': '**Refined Summary**\\n\\nThe CleverSync service is a critical component of the NoRedInk platform, responsible for synchronizing data between various services. The service is deployed in a monolithic architecture, with multiple features and flags managed through the `killswitch` mechanism.\\n\\nTo maintain the service, engineers can use the following tools:\\n\\n1. **CloudWatch logs**: Application logs and access logs are written to CloudWatch.\\n2. **SSH into app servers**: Engineers can SSH into app servers using the root SSH key found in 1Password or by finding IP addresses through the AWS UI.\\n3. **Maintenance mode**: The service can be put into maintenance mode to throttle requests to the quiz engine.\\n\\nIn case of an emergency, engineers can use the `killswitch` mechanism to quickly shut down specific features or the entire service. This is done by updating the relevant flags in the `killswitch` configuration file.\\n\\n**Deployment and Healthcheck**\\n\\nThe CleverSync service follows a regular Haskell Monorepo deploy process. After deployment, engineers perform healthchecks to ensure connectivity to databases and other critical systems.\\n\\n**Additional Resources**\\n\\nFor more information on the Drafts Service and Rostering Service, refer to the following resources:\\n\\n* All about the Drafts Service\\n* Rostering Service Firefighting Notes\\n\\nEngineers can also seek help through various Slack channels, including #ask-team-zen, #team-puffin, and #team-ink.'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)\n",
    "chain.invoke({\"input_documents\": raw_documents[:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Here is a refined summary based on the provided context:\\n'\n",
      " '\\n'\n",
      " \"**Firefighter's Checklist**\\n\"\n",
      " '\\n'\n",
      " 'As a firefighter, your role is to help resolve fires (technical issues) in '\n",
      " 'our system. Here are some key steps to follow:\\n'\n",
      " '\\n'\n",
      " '1. **Get Current Task**: Ensure you have a current task assigned by the '\n",
      " 'captain.\\n'\n",
      " '2. **Make Product Decisions**: If needed, pull in someone from #ask-support '\n",
      " 'or #ask-product for guidance.\\n'\n",
      " '3. **Update Channels**: Notify all relevant channels (including #fires) of '\n",
      " 'any updates or news.\\n'\n",
      " '4. **Keep Notes Up-to-Date**: Update notes in Engineering > Fires > In '\n",
      " 'Progress regularly.\\n'\n",
      " \"5. **Escalate if Stuck**: If you're stuck, escalate to Director of \"\n",
      " 'Engineering and/or Head of Product by phone for guidance.\\n'\n",
      " '\\n'\n",
      " '**When Fire is Resolved**\\n'\n",
      " '\\n'\n",
      " '1. **Update Channels**: Notify all relevant channels (including #fires) of '\n",
      " \"the fire's resolution.\\n\"\n",
      " '2. **Captain Hand-Off**: Pin the new captain to #fix-the-fire and ensure '\n",
      " 'notes are up-to-date and convey relevant information.\\n'\n",
      " '\\n'\n",
      " '**Last Captain**\\n'\n",
      " '\\n'\n",
      " '1. **Move Notes**: Move notes from Engineering > Fires > In Progress to '\n",
      " 'Engineering > Fires > Old Fires.\\n'\n",
      " '2. **Write Fire Follow-up**: Write a follow-up story (bug type) with the '\n",
      " 'label \"fire follow-up\" and link to the write-up template.\\n'\n",
      " '3. **Assign Eligible Writers**: Assign all firefighters as eligible people '\n",
      " 'who can write the follow-up report.\\n'\n",
      " '\\n'\n",
      " '**How Can I Help as a Non-ops?**\\n'\n",
      " '\\n'\n",
      " '1. **Pair/Observation**: Offer to pair or observe with ops to transfer '\n",
      " 'knowledge.\\n'\n",
      " '2. **Take Notes**: Offer to take notes and ask questions to understand the '\n",
      " 'process better.\\n'\n",
      " '\\n'\n",
      " 'This refined summary provides a clear checklist for firefighters to follow, '\n",
      " 'ensuring that fires are resolved efficiently and effectively.')\n"
     ]
    }
   ],
   "source": [
    "s = 'Here is a refined summary based on the provided context:\\n\\n**Firefighter\\'s Checklist**\\n\\nAs a firefighter, your role is to help resolve fires (technical issues) in our system. Here are some key steps to follow:\\n\\n1. **Get Current Task**: Ensure you have a current task assigned by the captain.\\n2. **Make Product Decisions**: If needed, pull in someone from #ask-support or #ask-product for guidance.\\n3. **Update Channels**: Notify all relevant channels (including #fires) of any updates or news.\\n4. **Keep Notes Up-to-Date**: Update notes in Engineering > Fires > In Progress regularly.\\n5. **Escalate if Stuck**: If you\\'re stuck, escalate to Director of Engineering and/or Head of Product by phone for guidance.\\n\\n**When Fire is Resolved**\\n\\n1. **Update Channels**: Notify all relevant channels (including #fires) of the fire\\'s resolution.\\n2. **Captain Hand-Off**: Pin the new captain to #fix-the-fire and ensure notes are up-to-date and convey relevant information.\\n\\n**Last Captain**\\n\\n1. **Move Notes**: Move notes from Engineering > Fires > In Progress to Engineering > Fires > Old Fires.\\n2. **Write Fire Follow-up**: Write a follow-up story (bug type) with the label \"fire follow-up\" and link to the write-up template.\\n3. **Assign Eligible Writers**: Assign all firefighters as eligible people who can write the follow-up report.\\n\\n**How Can I Help as a Non-ops?**\\n\\n1. **Pair/Observation**: Offer to pair or observe with ops to transfer knowledge.\\n2. **Take Notes**: Offer to take notes and ask questions to understand the process better.\\n\\nThis refined summary provides a clear checklist for firefighters to follow, ensuring that fires are resolved efficiently and effectively.'\n",
    "pprint.pp(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-documentation-explorer-4idgME2U-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
