{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dropbox\n",
    "import shutil\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "DOWNLOAD_FOLDER = \"content\"\n",
    "TEST_CONTENT_DROPBOX_FOLDER = \"LLM Doc Exp Test Content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbx = dropbox.Dropbox(getpass.getpass(\"Dropbox API Key:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Open AI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure local download folder exists, and delete its contents\n",
    "\n",
    "def create_download_folder():\n",
    "    if not os.path.exists(DOWNLOAD_FOLDER):\n",
    "        os.makedirs(DOWNLOAD_FOLDER)\n",
    "\n",
    "def clear_downloads_folder():\n",
    "    for filename in os.listdir(DOWNLOAD_FOLDER):\n",
    "        file_path = os.path.join(DOWNLOAD_FOLDER, filename)\n",
    "        print(file_path)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "create_download_folder()\n",
    "clear_downloads_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter dropbox paper docs and download to content file\n",
    "\n",
    "Download selected test paper docs using the [Dropbox API](https://www.dropbox.com/developers/documentation/http/documentation#paper-docs-download) and [Python SDK](https://dropbox-sdk-python.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "The dashboard for the Dropbox App used to do this can be found [here](https://www.dropbox.com/developers/apps/info/la3hq2wkhl5wx4m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dropbox.paper import ExportFormat, ListPaperDocsFilterBy\n",
    "\n",
    "def get_file_path(doc_id):\n",
    "    return os.path.join(DOWNLOAD_FOLDER, f\"{doc_titles[doc_id]}.md\")\n",
    "\n",
    "def download_doc(doc_id):\n",
    "    result = dbx.paper_docs_download_to_file(get_file_path(doc_id), doc_id, ExportFormat('markdown'))\n",
    "    print(f\"- downloaded '{result.title}'\")\n",
    "    return result\n",
    "\n",
    "print(\"Retrieving document IDs\")\n",
    "doc_ids = dbx.paper_docs_list(filter_by=ListPaperDocsFilterBy.docs_created).doc_ids\n",
    "print(f\"- {len(doc_ids)} documents found\")\n",
    "\n",
    "print(\"Filtering documents in folder\")\n",
    "docs_ids_in_folder = [doc_id for doc_id in doc_ids if TEST_CONTENT_DROPBOX_FOLDER in [folder.name for folder in dbx.paper_docs_get_folder_info(doc_id).folders or []]]\n",
    "print(f\"- {len(docs_ids_in_folder)} documents found in folder\")\n",
    "\n",
    "print(\"Retrieving document titles\")\n",
    "doc_titles = {doc_id: dbx.paper_docs_download(doc_id, ExportFormat('markdown'))[0].title for doc_id in docs_ids_in_folder}\n",
    "\n",
    "print(\"Downloading documents\")\n",
    "results = [download_doc(doc_id) for doc_id in docs_ids_in_folder]\n",
    "print(\"Download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG Q&A using the downloaded files\n",
    "\n",
    "Uses [this repo](https://github.com/AI-Maker-Space/LLM-Ops-Cohort-1/blob/main/Week%201/Tuesday/Barbie_Retrieval_Augmented_Question_Answering_(RAQA)_Assignment%20(Assignment%20Version).ipynb) as a reference.\n",
    "\n",
    "\n",
    "Additional Resources:\n",
    "https://github.com/zylon-ai/private-gpt/issues/358#issuecomment-1563663500\n",
    "https://python.langchain.com/docs/integrations/vectorstores/starrocks/\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders.directory import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown_path = \"content/How Express Entry works.md\"\n",
    "markdown_path = \"content\"\n",
    "\n",
    "# loader = TextLoader(markdown_path)\n",
    "loader = DirectoryLoader(markdown_path, glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "\n",
    "raw_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, # the character length of the chunk\n",
    "    chunk_overlap = 100, # the character length of the overlap between chunks\n",
    "    length_function = len, # the length function\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0])\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Creation\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/vectorstores/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.storage import LocalFileStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "core_embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    core_embeddings_model, store, namespace=core_embeddings_model.model\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(documents, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query on the vector store\n",
    "\n",
    "query = \"What do I need to send in my application for urgent citizenship processing?\"\n",
    "embedding_vector = core_embeddings_model.embed_query(query)\n",
    "docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)\n",
    "\n",
    "for page in docs:\n",
    "  print(page.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks import StdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = StdOutCallbackHandler()\n",
    "\n",
    "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    callbacks=[handler],\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_with_sources_chain({\"query\" : \"What do I need to send in my application for urgent citizenship processing?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-documentation-explorer-4idgME2U-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
