{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/learn/cookbook/en/rag_evaluation\n",
    "\n",
    "TODO: \n",
    "- [] Revise prompts for correct contextuality\n",
    "- [] Generate full dataset and publish to langsmith\n",
    "- [] Implement Langsmith [LLM-as-judge](https://docs.smith.langchain.com/old/evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import chain, islice\n",
    "\n",
    "from tqdm import tqdm\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.directory import DirectoryLoader\n",
    "from langchain_community.document_loaders.markdown import UnstructuredMarkdownLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GENERATIONS = 48  # We intentionally generate only 10 QA couples here for cost and time considerations\n",
    "MAX_CONCURRENCY = 6\n",
    "MAX_ANSWER_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs():\n",
    "    loader = DirectoryLoader(\n",
    "        \".content\", glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader\n",
    "    )\n",
    "    return loader.load()\n",
    "\n",
    "\n",
    "def chunk_docs(raw_documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "        Language.MARKDOWN,\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "    )\n",
    "\n",
    "    return text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_generation_prompt = \"\"\"\n",
    "Your task is to write a factoid question and an answer given a context.\n",
    "Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n",
    "Your factoid question should be formulated in the same style as questions users could ask in a search engine.\n",
    "This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Output:::\n",
    "Factoid question: (your factoid question)\n",
    "Answer: (your answer to the factoid question)\n",
    "\n",
    "Now here is the context.\n",
    "\n",
    "Context: {context}\\n\n",
    "Output:::\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = load_docs()\n",
    "documents = chunk_docs(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 48 QA couples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:00<00:00,  7.50s/it]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generating {N_GENERATIONS} QA couples...\")\n",
    "\n",
    "outputs = []\n",
    "samples = random.sample(documents, N_GENERATIONS)\n",
    "for pos in tqdm(range(0, len(samples), MAX_CONCURRENCY)):\n",
    "    batch = samples[pos:pos + MAX_CONCURRENCY]\n",
    "    output_QA_couples = llm.batch([QA_generation_prompt.format(context=sampled_context.page_content) for sampled_context in batch])\n",
    "    for i in range(len(output_QA_couples)):\n",
    "        try:\n",
    "            question = output_QA_couples[i].split(\"Factoid question: \")[-1].split(\"Answer: \")[0]\n",
    "            answer = output_QA_couples[i].split(\"Answer: \")[-1]\n",
    "            assert len(answer) < MAX_ANSWER_LENGTH, \"Answer is too long\"\n",
    "            outputs.append(\n",
    "                {\n",
    "                    \"context\": batch[i].page_content,\n",
    "                    \"question\": question.strip(),\n",
    "                    \"answer\": answer,\n",
    "                    \"source_doc\": batch[i].metadata[\"source\"],\n",
    "                }\n",
    "            )\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# for output in outputs:\n",
    "#     pprint.pp(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Setup critique agents\n",
    "The questions generated by the previous agent can have many flaws: we should do a quality check before validating these questions.\n",
    "\n",
    "We thus build critique agents that will rate each question on several criteria, given in [this paper](https://huggingface.co/papers/2312.10003):\n",
    "\n",
    "- **Groundedness:** can the question be answered from the given context?\n",
    "- **Relevance:** is the question relevant to users? For instance, \"What is the date when transformers 4.29.1 was released?\" is not relevant for ML practicioners.\n",
    "\n",
    "One last failure case we’ve noticed is when a function is tailored for the particular setting where the question was generated, but undecipherable by itself, like \"What is the name of the function used in this guide?\". We also build a critique agent for this criteria:\n",
    "\n",
    "- **Stand-alone:** is the question understandable free of any context, for someone with domain knowledge/Internet access? The opposite of this would be What is the function used in this article? for a question generated from a specific blog article.\n",
    "\n",
    "We systematically score functions with all these agents, and whenever the score is too low for any one of the agents, we eliminate the question from our eval dataset.\n",
    "\n",
    "*When asking the agents to output a score, we first ask them to produce its rationale. This will help us verify scores, but most importantly, asking it to first output rationale gives the model more tokens to think and elaborate an answer before summarizing it into a single score token.*\n",
    "\n",
    "We now build and run these critique agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_groundedness_critique_prompt = \"\"\"\n",
    "You will be given a context and a question.\n",
    "Your task is to provide a 'total rating' scoring how well one can answer the given question unambiguously with the given context.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not answerable at all given the context, and 5 means that the question is clearly and unambiguously answerable with the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here are the question and context.\n",
    "\n",
    "Question: {question}\\n\n",
    "Context: {context}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_relevance_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how useful this question can be to machine learning developers building NLP applications with the Hugging Face ecosystem.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not useful at all, and 5 means that the question is extremely useful.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_standalone_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how context-independant this question is.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question depends on additional information to be understood, and 5 means that the question makes sense by itself.\n",
    "For instance, if the question refers to a particular setting, like 'in the context' or 'in the document', the rating must be 1.\n",
    "The questions can contain obscure technical nouns or acronyms like Gradio, Hub, Hugging Face or Space and still be a 5: it must simply be clear to an operator with access to documentation what the question is about.\n",
    "\n",
    "For instance, \"What is the name of the checkpoint from which the ViT model is imported?\" should receive a 1, since there is an implicit mention of a context, thus the question is not independant from the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating critique for each QA couple...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [05:39<00:00, 14.14s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating critique for each QA couple...\")\n",
    "\n",
    "NUM_CRITERIA = 3\n",
    "\n",
    "def get_output_prompts(output):\n",
    "    return [\n",
    "        question_groundedness_critique_prompt.format(context=output[\"context\"], question=output[\"question\"]),\n",
    "        question_relevance_critique_prompt.format(question=output[\"question\"]),\n",
    "        question_standalone_critique_prompt.format(question=output[\"question\"]),\n",
    "    ]\n",
    "\n",
    "def batched(iterable, n):\n",
    "    # batched('ABCDEFG', 3) → ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    it = iter(iterable)\n",
    "    while batch := tuple(islice(it, n)):\n",
    "        yield batch\n",
    "\n",
    "scored_outputs = []\n",
    "max_output_concurrency = MAX_CONCURRENCY//NUM_CRITERIA\n",
    "for pos in tqdm(range(0, len(outputs), max_output_concurrency)):\n",
    "    output_batch = outputs[pos:pos + max_output_concurrency]\n",
    "    batch_prompts = list(chain.from_iterable(map(get_output_prompts, output_batch)))\n",
    "    results = llm.batch(batch_prompts)\n",
    "\n",
    "    for i, result_set in enumerate(batched(results, NUM_CRITERIA)):\n",
    "        try:\n",
    "            criterion_output = {**output_batch[i]}\n",
    "            for criterion, evaluation in zip([\"groundedness\", \"relevance\", \"standalone\"], result_set):\n",
    "                criterion_output[f\"{criterion}_score\"] = int(evaluation.split(\"Total rating: \")[-1].strip())\n",
    "                criterion_output[f\"{criterion}_eval\"] = evaluation.split(\"Total rating: \")[-2].split(\"Evaluation: \")[1]\n",
    "            scored_outputs.append(criterion_output)\n",
    "        except Exception as e:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset before filtering:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>groundedness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>standalone_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was hardcoded by Michael N to allow Terraform apply to run for tutorials on the ready-for-qa branch?</td>\n",
       "      <td>deployment_group_name in aws/codedeploy/output.tf</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the expected time for the topics cache key to expire?</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What time did Tessa report datadog results showing both drafts and tutorials request processing dropped to zero?</td>\n",
       "      <td>21:45 UTC 2019-11-12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What time was the request made by partnerships to apply the permanent fix?</td>\n",
       "      <td>5pm Pacific</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When did Hardy start working on a fix for the parallelism tutorial issue?</td>\n",
       "      <td>July 31, 2017, 6:53 PM</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What happens when you modify a Single-AZ deployment to a Multi-AZ deployment in Amazon RDS?</td>\n",
       "      <td>Amazon RDS takes a snapshot of the primary DB instance from your deployment and restores the snapshot into another Availability Zone.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What time was a frontend API change deployed on a page with autosaving?</td>\n",
       "      <td>8:45 PM</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the year of Imelda's friends' event?</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What requires all NewRelic checks to have no failures in order for a service to qualify as healthy?</td>\n",
       "      <td>Tracer.NewRelic.Health</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What was adjusted on the Oauth consent screen in Google Cloud Console?</td>\n",
       "      <td>The \"User Type\" was adjusted from external to internal.</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How many seconds did the deployment take at IP address 34.213.43.114?</td>\n",
       "      <td>0.999s</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is suggested as being more important in outage reporting?</td>\n",
       "      <td>Timely outage reporting.</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What happens to firefighters with remaining time during an end-of-call fire-drill?</td>\n",
       "      <td>They participate in a continuous risk identification and assessment process.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What version of RubyGems is compatible with Bundler 1.12.x?</td>\n",
       "      <td>&lt;= 2.6.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What happens to the demo account pool during the deployment period?</td>\n",
       "      <td>The demo account pool is wiped.</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What date did the 2023-06-15 admin pages down fire occur?</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What was Kristine trying to revert when the deploy failed?</td>\n",
       "      <td>The quiz engine service.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What service should you go to in the External Services tab to figure out which service started taking up a larger share of request time?</td>\n",
       "      <td>The DB service.</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What information should all notifications include?</td>\n",
       "      <td>predicted length of outage, predicted affected # users, cause of outage (for communication with customers), will any student data be lost (if known), Scope of impact such as what pages are being affected.</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What will students be unable to do due to an issue with QuizEngine?</td>\n",
       "      <td>Do quizzes.</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What was the primary suspect with a fix deployed to resolve network correlated memory spikes?</td>\n",
       "      <td>The primary suspect was pull/13550, which had a fix deployed in pull/13703.</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What happened to Kafka workers in 2023?</td>\n",
       "      <td>HQE Kafka workers stopped.</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Who informed Sam that all affected quizzes and diagnostics were archived?</td>\n",
       "      <td>Josh</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What was the cause of the site outage on February 7, 2023?</td>\n",
       "      <td>A PR changed how some data was being fetched and it lacked an index to make it performant.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What time was the deploy to prod complete?</td>\n",
       "      <td>20:50 UTC 2/21/18</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What is the ID of a specific grammar quiz question?</td>\n",
       "      <td>1483940677</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What are the two services that will be shut down at some point in the future in favor of Bugsnag?</td>\n",
       "      <td>Drafts Rollbar (same info as Bugsnag)</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What caused the outage on noredink.com on March 18, 2024?</td>\n",
       "      <td>The rostering database running out of storage space.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>When did Alexander announce that the fire was resolved?</td>\n",
       "      <td>September 22, 2017, at 8:10 AM.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What was the time when the incident started happening?</td>\n",
       "      <td>01:48 UTC, 2021-01-03</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Can you put a CSV into Gist directly?</td>\n",
       "      <td>Yes, it turns into a table with sortable columns.</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What caused a spike in Resque jobs on January 4, 2022?</td>\n",
       "      <td>Redis struggling with memory issues.</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What time is mentioned in the context?</td>\n",
       "      <td>10:40</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What is the version of node-sass?</td>\n",
       "      <td>3.8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What are the block sizes used in the backfill process?</td>\n",
       "      <td>2^8 - 2^11.</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>How many instances are currently planned to be scaled down?</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>How many users were affected by a bug in Canvas?</td>\n",
       "      <td>2.7k users</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What is the reason for disabling IPv6 in this context?</td>\n",
       "      <td>We think it's the wrong ipv version.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>How many questions were appended in sequence?</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>How many CI builds were fixed?</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>What was the primary mistake made during the analysis?</td>\n",
       "      <td>The primary mistake made during the analysis was not considering all possible root causes.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    question  \\\n",
       "0                                  What was hardcoded by Michael N to allow Terraform apply to run for tutorials on the ready-for-qa branch?   \n",
       "1                                                                              What is the expected time for the topics cache key to expire?   \n",
       "2                           What time did Tessa report datadog results showing both drafts and tutorials request processing dropped to zero?   \n",
       "3                                                                 What time was the request made by partnerships to apply the permanent fix?   \n",
       "4                                                                  When did Hardy start working on a fix for the parallelism tutorial issue?   \n",
       "5                                                What happens when you modify a Single-AZ deployment to a Multi-AZ deployment in Amazon RDS?   \n",
       "6                                                                    What time was a frontend API change deployed on a page with autosaving?   \n",
       "7                                                                                               What is the year of Imelda's friends' event?   \n",
       "8                                        What requires all NewRelic checks to have no failures in order for a service to qualify as healthy?   \n",
       "9                                                                     What was adjusted on the Oauth consent screen in Google Cloud Console?   \n",
       "10                                                                     How many seconds did the deployment take at IP address 34.213.43.114?   \n",
       "11                                                                            What is suggested as being more important in outage reporting?   \n",
       "12                                                        What happens to firefighters with remaining time during an end-of-call fire-drill?   \n",
       "13                                                                               What version of RubyGems is compatible with Bundler 1.12.x?   \n",
       "14                                                                       What happens to the demo account pool during the deployment period?   \n",
       "15                                                                                 What date did the 2023-06-15 admin pages down fire occur?   \n",
       "16                                                                                What was Kristine trying to revert when the deploy failed?   \n",
       "17  What service should you go to in the External Services tab to figure out which service started taking up a larger share of request time?   \n",
       "18                                                                                        What information should all notifications include?   \n",
       "19                                                                       What will students be unable to do due to an issue with QuizEngine?   \n",
       "20                                             What was the primary suspect with a fix deployed to resolve network correlated memory spikes?   \n",
       "21                                                                                                   What happened to Kafka workers in 2023?   \n",
       "22                                                                 Who informed Sam that all affected quizzes and diagnostics were archived?   \n",
       "23                                                                                What was the cause of the site outage on February 7, 2023?   \n",
       "24                                                                                                What time was the deploy to prod complete?   \n",
       "25                                                                                       What is the ID of a specific grammar quiz question?   \n",
       "26                                         What are the two services that will be shut down at some point in the future in favor of Bugsnag?   \n",
       "27                                                                                 What caused the outage on noredink.com on March 18, 2024?   \n",
       "28                                                                                   When did Alexander announce that the fire was resolved?   \n",
       "29                                                                                    What was the time when the incident started happening?   \n",
       "30                                                                                                     Can you put a CSV into Gist directly?   \n",
       "31                                                                                    What caused a spike in Resque jobs on January 4, 2022?   \n",
       "32                                                                                                    What time is mentioned in the context?   \n",
       "33                                                                                                         What is the version of node-sass?   \n",
       "34                                                                                    What are the block sizes used in the backfill process?   \n",
       "35                                                                               How many instances are currently planned to be scaled down?   \n",
       "36                                                                                          How many users were affected by a bug in Canvas?   \n",
       "37                                                                                    What is the reason for disabling IPv6 in this context?   \n",
       "38                                                                                             How many questions were appended in sequence?   \n",
       "39                                                                                                            How many CI builds were fixed?   \n",
       "40                                                                                    What was the primary mistake made during the analysis?   \n",
       "\n",
       "                                                                                                                                                                                                          answer  \\\n",
       "0                                                                                                                                                              deployment_group_name in aws/codedeploy/output.tf   \n",
       "1                                                                                                                                                                                                     10 minutes   \n",
       "2                                                                                                                                                                                           21:45 UTC 2019-11-12   \n",
       "3                                                                                                                                                                                                    5pm Pacific   \n",
       "4                                                                                                                                                                                         July 31, 2017, 6:53 PM   \n",
       "5                                                                          Amazon RDS takes a snapshot of the primary DB instance from your deployment and restores the snapshot into another Availability Zone.   \n",
       "6                                                                                                                                                                                                        8:45 PM   \n",
       "7                                                                                                                                                                                                           2023   \n",
       "8                                                                                                                                                                                         Tracer.NewRelic.Health   \n",
       "9                                                                                                                                                        The \"User Type\" was adjusted from external to internal.   \n",
       "10                                                                                                                                                                                                        0.999s   \n",
       "11                                                                                                                                                                                      Timely outage reporting.   \n",
       "12                                                                                                                                  They participate in a continuous risk identification and assessment process.   \n",
       "13                                                                                                                                                                                                      <= 2.6.1   \n",
       "14                                                                                                                                                                               The demo account pool is wiped.   \n",
       "15                                                                                                                                                                                                    2023-06-15   \n",
       "16                                                                                                                                                                                      The quiz engine service.   \n",
       "17                                                                                                                                                                                               The DB service.   \n",
       "18  predicted length of outage, predicted affected # users, cause of outage (for communication with customers), will any student data be lost (if known), Scope of impact such as what pages are being affected.   \n",
       "19                                                                                                                                                                                                   Do quizzes.   \n",
       "20                                                                                                                                   The primary suspect was pull/13550, which had a fix deployed in pull/13703.   \n",
       "21                                                                                                                                                                                    HQE Kafka workers stopped.   \n",
       "22                                                                                                                                                                                                          Josh   \n",
       "23                                                                                                                    A PR changed how some data was being fetched and it lacked an index to make it performant.   \n",
       "24                                                                                                                                                                                             20:50 UTC 2/21/18   \n",
       "25                                                                                                                                                                                                    1483940677   \n",
       "26                                                                                                                                                                         Drafts Rollbar (same info as Bugsnag)   \n",
       "27                                                                                                                                                          The rostering database running out of storage space.   \n",
       "28                                                                                                                                                                               September 22, 2017, at 8:10 AM.   \n",
       "29                                                                                                                                                                                         01:48 UTC, 2021-01-03   \n",
       "30                                                                                                                                                             Yes, it turns into a table with sortable columns.   \n",
       "31                                                                                                                                                                          Redis struggling with memory issues.   \n",
       "32                                                                                                                                                                                                         10:40   \n",
       "33                                                                                                                                                                                                         3.8.0   \n",
       "34                                                                                                                                                                                                   2^8 - 2^11.   \n",
       "35                                                                                                                                                                                                             2   \n",
       "36                                                                                                                                                                                                    2.7k users   \n",
       "37                                                                                                                                                                          We think it's the wrong ipv version.   \n",
       "38                                                                                                                                                                                                             2   \n",
       "39                                                                                                                                                                                                             5   \n",
       "40                                                                                                                    The primary mistake made during the analysis was not considering all possible root causes.   \n",
       "\n",
       "    groundedness_score  relevance_score  standalone_score  \n",
       "0                    5                2                 1  \n",
       "1                    5                2                 5  \n",
       "2                    4                1                 1  \n",
       "3                    2                1                 1  \n",
       "4                    5                2                 1  \n",
       "5                    5                1                 5  \n",
       "6                    5                2                 3  \n",
       "7                    1                1                 1  \n",
       "8                    5                3                 5  \n",
       "9                    5                2                 5  \n",
       "10                   5                1                 2  \n",
       "11                   5                2                 5  \n",
       "12                   5                1                 1  \n",
       "13                   5                1                 4  \n",
       "14                   4                2                 5  \n",
       "15                   5                1                 4  \n",
       "16                   2                1                 1  \n",
       "17                   5                4                 4  \n",
       "18                   5                3                 5  \n",
       "19                   5                2                 5  \n",
       "20                   5                3                 2  \n",
       "21                   4                1                 2  \n",
       "22                   5                2                 1  \n",
       "23                   5                1                 1  \n",
       "24                   5                2                 2  \n",
       "25                   1                2                 2  \n",
       "26                   5                2                 5  \n",
       "27                   5                1                 1  \n",
       "28                   5                1                 1  \n",
       "29                   5                1                 1  \n",
       "30                   5                4                 5  \n",
       "31                   5                2                 5  \n",
       "32                   5                3                 1  \n",
       "33                   5                1                 5  \n",
       "34                   5                4                 5  \n",
       "35                   5                1                 2  \n",
       "36                   2                1                 5  \n",
       "37                   5                1                 1  \n",
       "38                   5                2                 5  \n",
       "39                   1                1                 1  \n",
       "40                   2                2                 2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "Final evaluation dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>groundedness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>standalone_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What service should you go to in the External Services tab to figure out which service started taking up a larger share of request time?</td>\n",
       "      <td>The DB service.</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Can you put a CSV into Gist directly?</td>\n",
       "      <td>Yes, it turns into a table with sortable columns.</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What are the block sizes used in the backfill process?</td>\n",
       "      <td>2^8 - 2^11.</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    question  \\\n",
       "17  What service should you go to in the External Services tab to figure out which service started taking up a larger share of request time?   \n",
       "30                                                                                                     Can you put a CSV into Gist directly?   \n",
       "34                                                                                    What are the block sizes used in the backfill process?   \n",
       "\n",
       "                                               answer  groundedness_score  \\\n",
       "17                                    The DB service.                   5   \n",
       "30  Yes, it turns into a table with sortable columns.                   5   \n",
       "34                                        2^8 - 2^11.                   5   \n",
       "\n",
       "    relevance_score  standalone_score  \n",
       "17                4                 4  \n",
       "30                4                 5  \n",
       "34                4                 5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import datasets\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "generated_questions = pd.DataFrame.from_dict(scored_outputs)\n",
    "\n",
    "print(\"Evaluation dataset before filtering:\")\n",
    "display(\n",
    "    generated_questions[\n",
    "        [\n",
    "            \"question\",\n",
    "            \"answer\",\n",
    "            \"groundedness_score\",\n",
    "            \"relevance_score\",\n",
    "            \"standalone_score\",\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "generated_questions = generated_questions.loc[\n",
    "    (generated_questions[\"groundedness_score\"] >= 4)\n",
    "    & (generated_questions[\"relevance_score\"] >= 4)\n",
    "    & (generated_questions[\"standalone_score\"] >= 4)\n",
    "]\n",
    "print(\"============================================\")\n",
    "print(\"Final evaluation dataset:\")\n",
    "display(\n",
    "    generated_questions[\n",
    "        [\n",
    "            \"question\",\n",
    "            \"answer\",\n",
    "            \"groundedness_score\",\n",
    "            \"relevance_score\",\n",
    "            \"standalone_score\",\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# eval_dataset = datasets.Dataset.from_pandas(generated_questions, split=\"train\", preserve_index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-documentation-explorer-4idgME2U-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
